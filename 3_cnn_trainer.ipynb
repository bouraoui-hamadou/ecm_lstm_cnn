{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x19c227c5890>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools.tools import *\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "torch.manual_seed(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickled data\n",
    "with open(Path(\"data/data.bin\"), \"rb\") as f:\n",
    "    # Load the pickled data\n",
    "    data = pickle.load(f)\n",
    "data = flatten_dict(data) # flatten the dictionary\n",
    "data, min_max_dict = scale_dict(data) # scale the dictionary\n",
    "data_lad, data_ela = format_LGHE4C25B01(min_max_dict,constant_temperature=True) # load and format the charge discharge data\n",
    "datasets = {'lad': data_lad, 'ela': data_ela} # dictionary containing the above defined charge-discharge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparametertuning with Optuna\n",
    "def objective(trial, training_data, testing_data):\n",
    "    # Define search space\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 5)\n",
    "    num_neurons = trial.suggest_int('num_neurons', 32, 256) # num_neurons represents both number of neurons in the FC layer as well as the number of Kernels (see CNN class implementation)\n",
    "    sequence_length = trial.suggest_int(\"sequence_length\",1,10)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\",[32,64,128,256,512,1024])\n",
    "    epochs = trial.suggest_int(\"epochs\",10,50)\n",
    "    lr = trial.suggest_float(\"lr\",1e-4,1e-2,log=True)\n",
    "    \n",
    "    formatted_data = []\n",
    "    for i in range(0, len(training_data), 6):\n",
    "        sub_dic = get_sub_dictionary(training_data, i, print_message=False)\n",
    "        CNN_1D_data_format(sub_dic=sub_dic, formatted_data=formatted_data, sequence_length=sequence_length)\n",
    "\n",
    "    # Create model with hyperparameters\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    model = CNN_model(num_layers=num_layers, \n",
    "                      num_neurons=num_neurons, \n",
    "                      sequence_length=sequence_length)\n",
    "    model.to(device=device)\n",
    "\n",
    "    criterion = nn.MSELoss()  # Mean Squared Error Loss for regression tasks\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)  # Adam optimizer\n",
    "\n",
    "    print(f\"Trial parameters\\n{trial.params}\")\n",
    "\n",
    "    # Training and validation\n",
    "    training_set = CNN_1D_dataset(formatted_data)\n",
    "    train_loop(model=model, \n",
    "               dataset=training_set, \n",
    "               optimizer=optimizer, \n",
    "               criterion=criterion, \n",
    "               num_epochs=epochs, \n",
    "               device=device,\n",
    "               batch_size=batch_size)\n",
    "\n",
    "    # Testing\n",
    "    total_loss = 0\n",
    "    for set_name, dataset in testing_data.items():\n",
    "        for key, value in dataset.items():\n",
    "            formatted_data = []\n",
    "            CNN_1D_data_format(sub_dic=value, formatted_data=formatted_data, sequence_length=sequence_length)\n",
    "            testing_set = CNN_1D_dataset(formatted_data)\n",
    "            test_loss = test_model(model=model,\n",
    "                                        batch_size=batch_size,\n",
    "                                        test_set=testing_set,\n",
    "                                        device=device,\n",
    "                                        return_prediction=False)\n",
    "            total_loss += test_loss\n",
    "            print(f\"At temperature {key} the loss is {test_loss}\")\n",
    "    avg_loss = total_loss / (len(datasets[\"ela\"])+len(datasets[\"lad\"]))\n",
    "    # We want to minimize loss i.e. a smaller loss is better\n",
    "    return avg_loss, model, trial.params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-10 13:17:41,620]\u001b[0m A new study created in memory with name: no-name-fea310f9-18c5-4435-8271-53e55087a993\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters\n",
      "{'num_layers': 4, 'num_neurons': 33, 'sequence_length': 4, 'batch_size': 512, 'epochs': 21, 'lr': 0.0007123911116090734}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bouraoui\\Documents\\Job\\ecm_lstm_cnn\\tools\\tools.py:892: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  return torch.tensor(input, dtype=torch.float32), torch.tensor(output, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 0.004848709608275537\n",
      "Epoch: 1, Validation Loss: 1.890006898002765e-05\n",
      "Epoch: 2, Train Loss: 2.4802337323143655e-05\n",
      "Epoch: 2, Validation Loss: 1.673956000324224e-05\n",
      "Epoch: 3, Train Loss: 1.990167088553489e-05\n",
      "Epoch: 3, Validation Loss: 8.496157058041522e-06\n",
      "Epoch: 4, Train Loss: 1.7430953879864257e-05\n",
      "Epoch: 4, Validation Loss: 1.4348688380698652e-05\n",
      "Epoch: 5, Train Loss: 1.6279575289787577e-05\n",
      "Epoch: 5, Validation Loss: 2.048995849231745e-05\n",
      "Epoch: 6, Train Loss: 1.4155669793148719e-05\n",
      "Epoch: 6, Validation Loss: 1.1855078451005806e-05\n",
      "Epoch: 7, Train Loss: 1.2269480295149644e-05\n",
      "Epoch: 7, Validation Loss: 8.426450009731195e-06\n",
      "Epoch: 8, Train Loss: 1.099344134499679e-05\n",
      "Epoch: 8, Validation Loss: 1.721067378825422e-05\n",
      "Epoch: 9, Train Loss: 7.935015038718591e-06\n",
      "Epoch: 9, Validation Loss: 2.2751627697275113e-06\n",
      "Epoch: 10, Train Loss: 8.419543914660487e-06\n",
      "Epoch: 10, Validation Loss: 3.7542938366032144e-06\n",
      "Epoch: 11, Train Loss: 7.541080210519479e-06\n",
      "Epoch: 11, Validation Loss: 5.768303495522031e-06\n",
      "Epoch: 12, Train Loss: 6.073161361742849e-06\n",
      "Epoch: 12, Validation Loss: 9.626128117990283e-06\n",
      "Epoch: 13, Train Loss: 5.929503453571163e-06\n",
      "Epoch: 13, Validation Loss: 4.626127244690546e-06\n",
      "Epoch: 14, Train Loss: 5.4105484260279955e-06\n",
      "Epoch: 14, Validation Loss: 1.9452685941993653e-06\n",
      "Epoch: 15, Train Loss: 5.004588405271898e-06\n",
      "Epoch: 15, Validation Loss: 1.5798993130777377e-05\n",
      "Epoch: 16, Train Loss: 5.216308789927078e-06\n",
      "Epoch: 16, Validation Loss: 7.84974656316772e-06\n",
      "Epoch: 17, Train Loss: 3.984528914526343e-06\n",
      "Epoch: 17, Validation Loss: 1.523587688709152e-06\n",
      "Epoch: 18, Train Loss: 4.025351889546767e-06\n",
      "Epoch: 18, Validation Loss: 7.799440308086337e-06\n",
      "Epoch: 19, Train Loss: 3.884945560835427e-06\n",
      "Epoch: 19, Validation Loss: 2.276037325449507e-06\n",
      "Epoch: 20, Train Loss: 3.1815704990199214e-06\n",
      "Epoch: 20, Validation Loss: 4.8006039402110295e-06\n",
      "Epoch: 21, Train Loss: 3.3105110376382664e-06\n",
      "Epoch: 21, Validation Loss: 3.805074679954238e-06\n",
      "At temperature 15 the loss is 0.0007686499696278174\n",
      "At temperature 25 the loss is 0.0008366231285931876\n",
      "At temperature 45 the loss is 0.0008642364198914782\n",
      "At temperature 15 the loss is 0.0007858762543368026\n",
      "At temperature 25 the loss is 0.0008538006322024474\n",
      "At temperature 45 the loss is 0.0007038092011374498\n",
      "Trial 1/100 completed. Remaining trials: 99\n",
      "Trial parameters\n",
      "{'num_layers': 1, 'num_neurons': 47, 'sequence_length': 6, 'batch_size': 256, 'epochs': 14, 'lr': 0.006453946348493673}\n",
      "Epoch: 1, Train Loss: 0.0006285021858071999\n",
      "Epoch: 1, Validation Loss: 9.762398065691936e-06\n",
      "Epoch: 2, Train Loss: 2.9029499789604674e-05\n",
      "Epoch: 2, Validation Loss: 1.4408550628566876e-05\n",
      "Epoch: 3, Train Loss: 2.127847452593954e-05\n",
      "Epoch: 3, Validation Loss: 7.669381869556859e-06\n",
      "Epoch: 4, Train Loss: 1.710167923569768e-05\n",
      "Epoch: 4, Validation Loss: 5.167115445388423e-05\n",
      "Epoch: 5, Train Loss: 1.1859423435614518e-05\n",
      "Epoch: 5, Validation Loss: 6.875036309199875e-06\n",
      "Epoch: 6, Train Loss: 9.761196415717004e-06\n",
      "Epoch: 6, Validation Loss: 1.9671791897130557e-05\n",
      "Epoch: 7, Train Loss: 8.130371306686425e-06\n",
      "Epoch: 7, Validation Loss: 9.535034387785714e-06\n",
      "Epoch: 8, Train Loss: 7.130377775769437e-06\n",
      "Epoch: 8, Validation Loss: 2.4724188024413186e-06\n",
      "Epoch: 9, Train Loss: 5.719729165382977e-06\n",
      "Epoch: 9, Validation Loss: 1.7328984543865838e-05\n",
      "Epoch: 10, Train Loss: 5.92613238771371e-06\n",
      "Epoch: 10, Validation Loss: 2.5754145838163822e-06\n",
      "Epoch: 11, Train Loss: 5.703039666859414e-06\n",
      "Epoch: 11, Validation Loss: 3.732535597722652e-06\n",
      "Epoch: 12, Train Loss: 5.6221202734243805e-06\n",
      "Epoch: 12, Validation Loss: 5.932593562692487e-06\n",
      "Epoch: 13, Train Loss: 5.1790331976336695e-06\n",
      "Epoch: 13, Validation Loss: 2.4362995656546534e-06\n",
      "Epoch: 14, Train Loss: 4.79168569964324e-06\n",
      "Epoch: 14, Validation Loss: 2.8058821764573824e-06\n",
      "At temperature 15 the loss is 0.0008052977215261625\n",
      "At temperature 25 the loss is 0.0007792196258383969\n",
      "At temperature 45 the loss is 0.0007072783393017413\n",
      "At temperature 15 the loss is 0.0008878701149559104\n",
      "At temperature 25 the loss is 0.0008426478621109963\n",
      "At temperature 45 the loss is 0.0008308495317909216\n",
      "Number of no improvement trials is 1\n",
      "Trial 2/100 completed. Remaining trials: 98\n",
      "Trial parameters\n",
      "{'num_layers': 4, 'num_neurons': 45, 'sequence_length': 4, 'batch_size': 32, 'epochs': 10, 'lr': 0.00011894815762216467}\n",
      "Epoch: 1, Train Loss: 0.0012061542228635955\n",
      "Epoch: 1, Validation Loss: 1.2431885618486501e-05\n",
      "Epoch: 2, Train Loss: 1.0729334744648333e-05\n",
      "Epoch: 2, Validation Loss: 2.630306741454295e-06\n",
      "Epoch: 3, Train Loss: 6.3339846179362935e-06\n",
      "Epoch: 3, Validation Loss: 2.6643146225813695e-06\n",
      "Epoch: 4, Train Loss: 4.6045622193652815e-06\n",
      "Epoch: 4, Validation Loss: 2.289536226253617e-06\n",
      "Epoch: 5, Train Loss: 3.987320262587586e-06\n",
      "Epoch: 5, Validation Loss: 1.6608117971431282e-06\n",
      "Epoch: 6, Train Loss: 2.985299838902582e-06\n",
      "Epoch: 6, Validation Loss: 2.2290259593766853e-06\n",
      "Epoch: 7, Train Loss: 2.5836305192927634e-06\n",
      "Epoch: 7, Validation Loss: 1.3971280137136564e-06\n",
      "Epoch: 8, Train Loss: 2.405842223512779e-06\n",
      "Epoch: 8, Validation Loss: 2.7065551687596853e-06\n",
      "Epoch: 9, Train Loss: 2.015789030597758e-06\n",
      "Epoch: 9, Validation Loss: 9.948144824784245e-07\n",
      "Epoch: 10, Train Loss: 1.81470998132316e-06\n",
      "Epoch: 10, Validation Loss: 2.292550372860051e-06\n",
      "At temperature 15 the loss is 0.0007740781297751005\n",
      "At temperature 25 the loss is 0.0007427866656570938\n",
      "At temperature 45 the loss is 0.000703047321681449\n",
      "At temperature 15 the loss is 0.0009006588126343945\n",
      "At temperature 25 the loss is 0.0008520886774476821\n",
      "At temperature 45 the loss is 0.0007913729517577233\n",
      "Trial 3/100 completed. Remaining trials: 97\n",
      "Trial parameters\n",
      "{'num_layers': 1, 'num_neurons': 148, 'sequence_length': 10, 'batch_size': 1024, 'epochs': 16, 'lr': 0.0013891432923179234}\n",
      "Epoch: 1, Train Loss: 0.004760482433241044\n",
      "Epoch: 1, Validation Loss: 0.00015134457217205163\n",
      "Epoch: 2, Train Loss: 7.702510125679485e-05\n",
      "Epoch: 2, Validation Loss: 3.914872031395145e-05\n",
      "Epoch: 3, Train Loss: 2.7893159235876955e-05\n",
      "Epoch: 3, Validation Loss: 1.9246550765803405e-05\n",
      "Epoch: 4, Train Loss: 1.4495243244852996e-05\n",
      "Epoch: 4, Validation Loss: 1.001325406416411e-05\n",
      "Epoch: 5, Train Loss: 1.8715258838204227e-05\n",
      "Epoch: 5, Validation Loss: 9.725629533829311e-06\n",
      "Epoch: 6, Train Loss: 4.5331725623129464e-05\n",
      "Epoch: 6, Validation Loss: 3.545066546635586e-05\n",
      "Epoch: 7, Train Loss: 4.6685581054155594e-05\n",
      "Epoch: 7, Validation Loss: 8.008374716206615e-06\n",
      "Epoch: 8, Train Loss: 3.381361912430144e-05\n",
      "Epoch: 8, Validation Loss: 2.7973564918561428e-05\n",
      "Epoch: 9, Train Loss: 2.7330149179252363e-05\n",
      "Epoch: 9, Validation Loss: 9.170450002424804e-06\n",
      "Epoch: 10, Train Loss: 2.7117548306507234e-05\n",
      "Epoch: 10, Validation Loss: 6.557101896451983e-06\n",
      "Epoch: 11, Train Loss: 2.3977262614528476e-05\n",
      "Epoch: 11, Validation Loss: 6.647778636401672e-06\n",
      "Epoch: 12, Train Loss: 1.803194783343859e-05\n",
      "Epoch: 12, Validation Loss: 2.2899973882911806e-06\n",
      "Epoch: 13, Train Loss: 1.7988178034667976e-05\n",
      "Epoch: 13, Validation Loss: 4.105551299243555e-06\n",
      "Epoch: 14, Train Loss: 1.512005721840397e-05\n",
      "Epoch: 14, Validation Loss: 3.0980550324224333e-05\n",
      "Epoch: 15, Train Loss: 1.4654725443449065e-05\n",
      "Epoch: 15, Validation Loss: 2.2817843145697478e-06\n",
      "Epoch: 16, Train Loss: 1.5053893243611047e-05\n",
      "Epoch: 16, Validation Loss: 2.4028210397495893e-06\n",
      "At temperature 15 the loss is 0.0007853692282382822\n",
      "At temperature 25 the loss is 0.0007777110442310169\n",
      "At temperature 45 the loss is 0.0007676752803407991\n",
      "At temperature 15 the loss is 0.0010618344448713206\n",
      "At temperature 25 the loss is 0.0009268548166635975\n",
      "At temperature 45 the loss is 0.0008220362139003224\n",
      "Number of no improvement trials is 1\n",
      "Trial 4/100 completed. Remaining trials: 96\n",
      "Trial parameters\n",
      "{'num_layers': 5, 'num_neurons': 167, 'sequence_length': 1, 'batch_size': 32, 'epochs': 42, 'lr': 0.00012452326533049708}\n",
      "Epoch: 1, Train Loss: 0.0012866796292805758\n",
      "Epoch: 1, Validation Loss: 2.301239318636183e-05\n",
      "Epoch: 2, Train Loss: 2.2027510541077836e-05\n",
      "Epoch: 2, Validation Loss: 1.2011605346764381e-05\n",
      "Epoch: 3, Train Loss: 1.4125724679028346e-05\n",
      "Epoch: 3, Validation Loss: 3.7020880573452285e-06\n",
      "Epoch: 4, Train Loss: 1.0065515407544813e-05\n",
      "Epoch: 4, Validation Loss: 3.2214337045468877e-06\n",
      "Epoch: 5, Train Loss: 7.783674559293196e-06\n",
      "Epoch: 5, Validation Loss: 6.424690271398217e-06\n",
      "Epoch: 6, Train Loss: 5.738907867977609e-06\n",
      "Epoch: 6, Validation Loss: 4.1989307287666176e-06\n",
      "Epoch: 7, Train Loss: 5.072712757086771e-06\n",
      "Epoch: 7, Validation Loss: 1.751473695820451e-06\n",
      "Epoch: 8, Train Loss: 4.034083394682837e-06\n",
      "Epoch: 8, Validation Loss: 1.2610809175352045e-06\n",
      "Epoch: 9, Train Loss: 3.906661194389403e-06\n",
      "Epoch: 9, Validation Loss: 2.141012251800855e-06\n",
      "Epoch: 10, Train Loss: 3.434864032016717e-06\n",
      "Epoch: 10, Validation Loss: 6.732276374717904e-06\n",
      "Epoch: 11, Train Loss: 2.98038146988622e-06\n",
      "Epoch: 11, Validation Loss: 1.7459979915903755e-06\n",
      "Epoch: 12, Train Loss: 2.8674914589415675e-06\n",
      "Epoch: 12, Validation Loss: 9.198293523162265e-07\n",
      "Epoch: 13, Train Loss: 2.4472441504999814e-06\n",
      "Epoch: 13, Validation Loss: 2.006898844060574e-06\n",
      "Epoch: 14, Train Loss: 2.3631565694803863e-06\n",
      "Epoch: 14, Validation Loss: 1.221751750016191e-06\n",
      "Epoch: 15, Train Loss: 2.1978767201206166e-06\n",
      "Epoch: 15, Validation Loss: 8.573354248198638e-07\n",
      "Epoch: 16, Train Loss: 1.940139324381567e-06\n",
      "Epoch: 16, Validation Loss: 9.191929706576673e-07\n",
      "Epoch: 17, Train Loss: 1.946304092606688e-06\n",
      "Epoch: 17, Validation Loss: 7.596002279599176e-07\n",
      "Epoch: 18, Train Loss: 1.8359816407445553e-06\n",
      "Epoch: 18, Validation Loss: 1.2196105806210043e-06\n",
      "Epoch: 19, Train Loss: 1.6819167504997896e-06\n",
      "Epoch: 19, Validation Loss: 9.351236462691859e-07\n",
      "Epoch: 20, Train Loss: 1.6604161060097248e-06\n",
      "Epoch: 20, Validation Loss: 2.353839528098079e-06\n",
      "Epoch: 21, Train Loss: 1.672616007474698e-06\n",
      "Epoch: 21, Validation Loss: 2.0994995148153502e-06\n",
      "Epoch: 22, Train Loss: 1.531278667208718e-06\n",
      "Epoch: 22, Validation Loss: 6.314240699088246e-07\n",
      "Epoch: 23, Train Loss: 1.417512275362967e-06\n",
      "Epoch: 23, Validation Loss: 7.023429299558067e-07\n",
      "Epoch: 24, Train Loss: 1.3717847408037388e-06\n",
      "Epoch: 24, Validation Loss: 6.194595531789304e-07\n",
      "Epoch: 25, Train Loss: 1.3702752052769433e-06\n",
      "Epoch: 25, Validation Loss: 5.783997804698991e-07\n",
      "Epoch: 26, Train Loss: 1.335832481912563e-06\n",
      "Epoch: 26, Validation Loss: 5.79228727486983e-07\n",
      "Epoch: 27, Train Loss: 1.1826846489224218e-06\n",
      "Epoch: 27, Validation Loss: 7.897468368964814e-07\n",
      "Epoch: 28, Train Loss: 1.3635834639086114e-06\n",
      "Epoch: 28, Validation Loss: 1.2536849208500394e-06\n",
      "Epoch: 29, Train Loss: 1.1749012655396813e-06\n",
      "Epoch: 29, Validation Loss: 2.028728098549088e-06\n",
      "Epoch: 30, Train Loss: 1.1638208947514543e-06\n",
      "Epoch: 30, Validation Loss: 1.376963168882984e-06\n",
      "Epoch: 31, Train Loss: 1.1558835080685704e-06\n",
      "Epoch: 31, Validation Loss: 9.233637848206867e-07\n",
      "Epoch: 32, Train Loss: 1.1335954515980562e-06\n",
      "Epoch: 32, Validation Loss: 5.029948840474657e-07\n",
      "Epoch: 33, Train Loss: 1.0484499691429064e-06\n",
      "Epoch: 33, Validation Loss: 9.209955213003765e-07\n",
      "Epoch: 34, Train Loss: 1.0926229665158981e-06\n",
      "Epoch: 34, Validation Loss: 2.9988785242853494e-07\n",
      "Epoch: 35, Train Loss: 1.085222109193435e-06\n",
      "Epoch: 35, Validation Loss: 4.990572998374531e-07\n",
      "Epoch: 36, Train Loss: 1.0085157320324632e-06\n",
      "Epoch: 36, Validation Loss: 4.355899405740731e-07\n",
      "Epoch: 37, Train Loss: 1.0890947578099365e-06\n",
      "Epoch: 37, Validation Loss: 3.4200645744828476e-07\n",
      "Epoch: 38, Train Loss: 1.0208107276549618e-06\n",
      "Epoch: 38, Validation Loss: 4.4640494029610737e-07\n",
      "Epoch: 39, Train Loss: 1.0202298384073153e-06\n",
      "Epoch: 39, Validation Loss: 6.861201719955438e-07\n",
      "Epoch: 40, Train Loss: 1.0069799311838784e-06\n",
      "Epoch: 40, Validation Loss: 1.2094446346492416e-06\n",
      "Epoch: 41, Train Loss: 9.671961951789244e-07\n",
      "Epoch: 41, Validation Loss: 5.755287304597414e-07\n",
      "Epoch: 42, Train Loss: 9.086665356898417e-07\n",
      "Epoch: 42, Validation Loss: 2.9493489239199194e-07\n",
      "At temperature 15 the loss is 0.0008252634148453505\n",
      "At temperature 25 the loss is 0.0008065991366009278\n",
      "At temperature 45 the loss is 0.0007810467531509279\n",
      "At temperature 15 the loss is 0.0008442501002611612\n",
      "At temperature 25 the loss is 0.0007866754552640825\n",
      "At temperature 45 the loss is 0.000710296371702731\n",
      "Trial 5/100 completed. Remaining trials: 95\n",
      "Trial parameters\n",
      "{'num_layers': 5, 'num_neurons': 107, 'sequence_length': 8, 'batch_size': 64, 'epochs': 37, 'lr': 0.000693382652310114}\n",
      "Epoch: 1, Train Loss: 0.00034723797474832646\n",
      "Epoch: 1, Validation Loss: 2.4477168571000643e-05\n",
      "Epoch: 2, Train Loss: 1.544981368600085e-05\n",
      "Epoch: 2, Validation Loss: 2.402743139031824e-06\n",
      "Epoch: 3, Train Loss: 7.765369818113224e-06\n",
      "Epoch: 3, Validation Loss: 9.231975143941912e-06\n",
      "Epoch: 4, Train Loss: 6.015207442439485e-06\n",
      "Epoch: 4, Validation Loss: 7.86597701941169e-06\n",
      "Epoch: 5, Train Loss: 4.870708137079817e-06\n",
      "Epoch: 5, Validation Loss: 3.2437747335667154e-05\n",
      "Epoch: 6, Train Loss: 3.857235362229137e-06\n",
      "Epoch: 6, Validation Loss: 5.002863645533162e-06\n",
      "Epoch: 7, Train Loss: 3.34678180831023e-06\n",
      "Epoch: 7, Validation Loss: 2.2897864994902406e-06\n",
      "Epoch: 8, Train Loss: 3.1972757345278923e-06\n",
      "Epoch: 8, Validation Loss: 4.001555035437636e-07\n",
      "Epoch: 9, Train Loss: 2.6838783539087507e-06\n",
      "Epoch: 9, Validation Loss: 8.482959812163782e-06\n",
      "Epoch: 10, Train Loss: 2.34452530404593e-06\n",
      "Epoch: 10, Validation Loss: 6.469883719556928e-07\n",
      "Epoch: 11, Train Loss: 2.224829212230446e-06\n",
      "Epoch: 11, Validation Loss: 4.240536518687391e-07\n",
      "Epoch: 12, Train Loss: 2.1404737485376857e-06\n",
      "Epoch: 12, Validation Loss: 9.130907053394361e-07\n",
      "Epoch: 13, Train Loss: 1.972804219494994e-06\n",
      "Epoch: 13, Validation Loss: 2.6197983456150642e-06\n",
      "Epoch: 14, Train Loss: 1.9042744113260015e-06\n",
      "Epoch: 14, Validation Loss: 6.501315650591087e-07\n",
      "Epoch: 15, Train Loss: 1.761022858639456e-06\n",
      "Epoch: 15, Validation Loss: 1.0476094602032584e-06\n",
      "Epoch: 16, Train Loss: 1.7324215752547786e-06\n",
      "Epoch: 16, Validation Loss: 8.369965697278125e-07\n",
      "Epoch: 17, Train Loss: 1.5339191139109984e-06\n",
      "Epoch: 17, Validation Loss: 2.323320920295206e-06\n",
      "Epoch: 18, Train Loss: 1.4986332682459556e-06\n",
      "Epoch: 18, Validation Loss: 1.500047117579918e-06\n",
      "Epoch: 19, Train Loss: 1.3725305854484456e-06\n",
      "Epoch: 19, Validation Loss: 3.644499133842078e-07\n",
      "Epoch: 20, Train Loss: 1.3098544047600335e-06\n",
      "Epoch: 20, Validation Loss: 4.315020183206294e-07\n",
      "Epoch: 21, Train Loss: 1.401474543011914e-06\n",
      "Epoch: 21, Validation Loss: 6.102087162294808e-07\n",
      "Epoch: 22, Train Loss: 1.2595731910800758e-06\n",
      "Epoch: 22, Validation Loss: 8.115486716232539e-07\n",
      "Epoch: 23, Train Loss: 1.2178428874474187e-06\n",
      "Epoch: 23, Validation Loss: 6.64949982047968e-07\n",
      "Epoch: 24, Train Loss: 1.2169564667752336e-06\n",
      "Epoch: 24, Validation Loss: 3.7671314171520937e-07\n",
      "Epoch: 25, Train Loss: 1.2069825721447236e-06\n",
      "Epoch: 25, Validation Loss: 4.0161133355111656e-07\n",
      "Epoch: 26, Train Loss: 1.180785773236802e-06\n",
      "Epoch: 26, Validation Loss: 2.715494195186116e-07\n",
      "Epoch: 27, Train Loss: 1.09215833729044e-06\n",
      "Epoch: 27, Validation Loss: 4.142678012815428e-06\n",
      "Epoch: 28, Train Loss: 1.0892835571005297e-06\n",
      "Epoch: 28, Validation Loss: 7.423036951032332e-07\n",
      "Epoch: 29, Train Loss: 1.0677240096963834e-06\n",
      "Epoch: 29, Validation Loss: 6.53215319427967e-07\n",
      "Epoch: 30, Train Loss: 1.0988419688733064e-06\n",
      "Epoch: 30, Validation Loss: 5.415264111003172e-07\n",
      "Epoch: 31, Train Loss: 1.017563064445692e-06\n",
      "Epoch: 31, Validation Loss: 3.9466662198255795e-07\n",
      "Epoch: 32, Train Loss: 9.746492915020577e-07\n",
      "Epoch: 32, Validation Loss: 4.2584052022036207e-07\n",
      "Epoch: 33, Train Loss: 1.0203448328504975e-06\n",
      "Epoch: 33, Validation Loss: 6.591344292822127e-07\n",
      "Epoch: 34, Train Loss: 9.300766643293612e-07\n",
      "Epoch: 34, Validation Loss: 8.421968525555047e-07\n",
      "Epoch: 35, Train Loss: 8.824640804240613e-07\n",
      "Epoch: 35, Validation Loss: 1.5707439789687157e-06\n",
      "Epoch: 36, Train Loss: 9.060301323258792e-07\n",
      "Epoch: 36, Validation Loss: 7.254512938381049e-07\n",
      "Epoch: 37, Train Loss: 8.730430980919245e-07\n",
      "Epoch: 37, Validation Loss: 1.26404235284751e-06\n",
      "At temperature 15 the loss is 0.000790016796719362\n",
      "At temperature 25 the loss is 0.0007591928618700459\n",
      "At temperature 45 the loss is 0.0007525254337885847\n",
      "At temperature 15 the loss is 0.0009067972410454839\n",
      "At temperature 25 the loss is 0.0008395024791922011\n",
      "At temperature 45 the loss is 0.0007598147569934689\n",
      "Number of no improvement trials is 1\n",
      "Trial 6/100 completed. Remaining trials: 94\n",
      "Trial parameters\n",
      "{'num_layers': 5, 'num_neurons': 187, 'sequence_length': 8, 'batch_size': 1024, 'epochs': 32, 'lr': 0.0008437880786407895}\n",
      "Epoch: 1, Train Loss: 0.0028026177398707227\n",
      "Epoch: 1, Validation Loss: 1.034319002094679e-05\n",
      "Epoch: 2, Train Loss: 2.2166391060370207e-05\n",
      "Epoch: 2, Validation Loss: 3.5554384848475854e-05\n",
      "Epoch: 3, Train Loss: 7.263231195209623e-05\n",
      "Epoch: 3, Validation Loss: 7.135809403216062e-05\n",
      "Epoch: 4, Train Loss: 4.635963648139542e-05\n",
      "Epoch: 4, Validation Loss: 5.1122358607984605e-05\n",
      "Epoch: 5, Train Loss: 5.6751112840469844e-05\n",
      "Epoch: 5, Validation Loss: 1.7251415679850853e-05\n",
      "Epoch: 6, Train Loss: 2.715396914777612e-05\n",
      "Epoch: 6, Validation Loss: 9.672341142206565e-06\n",
      "Epoch: 7, Train Loss: 3.051979924759604e-05\n",
      "Epoch: 7, Validation Loss: 5.089335046008694e-06\n",
      "Epoch: 8, Train Loss: 2.6921116844439864e-05\n",
      "Epoch: 8, Validation Loss: 0.0002591215655481243\n",
      "Epoch: 9, Train Loss: 2.229956335205243e-05\n",
      "Epoch: 9, Validation Loss: 2.4499571048125155e-05\n",
      "Epoch: 10, Train Loss: 2.209814649587837e-05\n",
      "Epoch: 10, Validation Loss: 6.1839701272533265e-06\n",
      "Epoch: 11, Train Loss: 1.4254360490330818e-05\n",
      "Epoch: 11, Validation Loss: 1.2837253604943392e-05\n",
      "Epoch: 12, Train Loss: 1.7639036375346794e-05\n",
      "Epoch: 12, Validation Loss: 3.1589065229461295e-06\n",
      "Epoch: 13, Train Loss: 1.2031016866866579e-05\n",
      "Epoch: 13, Validation Loss: 1.2383660259600909e-06\n",
      "Epoch: 14, Train Loss: 1.4611925228792284e-05\n",
      "Epoch: 14, Validation Loss: 1.9580955416897095e-06\n",
      "Epoch: 15, Train Loss: 9.155863191714363e-06\n",
      "Epoch: 15, Validation Loss: 4.38166329084937e-06\n",
      "Epoch: 16, Train Loss: 1.1230673140675788e-05\n",
      "Epoch: 16, Validation Loss: 1.4659522506683914e-06\n",
      "Epoch: 17, Train Loss: 7.971946507854014e-06\n",
      "Epoch: 17, Validation Loss: 1.5156321217027088e-06\n",
      "Epoch: 18, Train Loss: 7.86322294189531e-06\n",
      "Epoch: 18, Validation Loss: 2.3644597302408418e-06\n",
      "Epoch: 19, Train Loss: 7.949086329346247e-06\n",
      "Epoch: 19, Validation Loss: 1.5443243865379347e-06\n",
      "Epoch: 20, Train Loss: 7.140652167573286e-06\n",
      "Epoch: 20, Validation Loss: 6.54675690420434e-06\n",
      "Epoch: 21, Train Loss: 6.742316275216257e-06\n",
      "Epoch: 21, Validation Loss: 3.3549711782395057e-06\n",
      "Epoch: 22, Train Loss: 1.8722345927228016e-05\n",
      "Epoch: 22, Validation Loss: 1.384352114333051e-06\n",
      "Epoch: 23, Train Loss: 4.993799295873316e-06\n",
      "Epoch: 23, Validation Loss: 1.6489895448760912e-06\n",
      "Epoch: 24, Train Loss: 5.037841637297427e-06\n",
      "Epoch: 24, Validation Loss: 1.3723025490101252e-06\n",
      "Epoch: 25, Train Loss: 4.828885937871257e-06\n",
      "Epoch: 25, Validation Loss: 7.256075432958741e-07\n",
      "Epoch: 26, Train Loss: 5.277782107858764e-06\n",
      "Epoch: 26, Validation Loss: 5.204031546331168e-07\n",
      "Epoch: 27, Train Loss: 5.057678819305849e-06\n",
      "Epoch: 27, Validation Loss: 3.8146141008128634e-06\n",
      "Epoch: 28, Train Loss: 4.225437637061665e-06\n",
      "Epoch: 28, Validation Loss: 6.270310866627477e-06\n",
      "Epoch: 29, Train Loss: 4.523872128648309e-06\n",
      "Epoch: 29, Validation Loss: 9.126747962431706e-07\n",
      "Epoch: 30, Train Loss: 3.995286203869031e-06\n",
      "Epoch: 30, Validation Loss: 9.391817337347294e-05\n",
      "Epoch: 31, Train Loss: 4.037282620376438e-06\n",
      "Epoch: 31, Validation Loss: 2.757561956085054e-06\n",
      "Epoch: 32, Train Loss: 4.016033642528782e-06\n",
      "Epoch: 32, Validation Loss: 5.463910756229343e-06\n",
      "At temperature 15 the loss is 0.0007968458622516747\n",
      "At temperature 25 the loss is 0.0007182610603525642\n",
      "At temperature 45 the loss is 0.0007620678840215656\n",
      "At temperature 15 the loss is 0.0012213224498819645\n",
      "At temperature 25 the loss is 0.001005131037924333\n",
      "At temperature 45 the loss is 0.0008599400286419206\n",
      "Number of no improvement trials is 2\n",
      "Trial 7/100 completed. Remaining trials: 93\n",
      "Trial parameters\n",
      "{'num_layers': 3, 'num_neurons': 204, 'sequence_length': 6, 'batch_size': 64, 'epochs': 13, 'lr': 0.0002865347774198664}\n",
      "Epoch: 1, Train Loss: 0.00036721577788874734\n",
      "Epoch: 1, Validation Loss: 1.7928739319135492e-05\n",
      "Epoch: 2, Train Loss: 1.1833134560892529e-05\n",
      "Epoch: 2, Validation Loss: 4.1361640713323225e-06\n",
      "Epoch: 3, Train Loss: 6.978558242284352e-06\n",
      "Epoch: 3, Validation Loss: 4.343167125668481e-06\n",
      "Epoch: 4, Train Loss: 4.6523858952136165e-06\n",
      "Epoch: 4, Validation Loss: 1.4362903893421849e-06\n",
      "Epoch: 5, Train Loss: 3.479112379909055e-06\n",
      "Epoch: 5, Validation Loss: 2.185144889299049e-06\n",
      "Epoch: 6, Train Loss: 2.8874701336267873e-06\n",
      "Epoch: 6, Validation Loss: 3.871880613670421e-06\n",
      "Epoch: 7, Train Loss: 2.433852293978697e-06\n",
      "Epoch: 7, Validation Loss: 1.4614191877590452e-06\n",
      "Epoch: 8, Train Loss: 2.2753131125691606e-06\n",
      "Epoch: 8, Validation Loss: 1.975746544618916e-06\n",
      "Epoch: 9, Train Loss: 1.9965729907150776e-06\n",
      "Epoch: 9, Validation Loss: 9.955163945324646e-07\n",
      "Epoch: 10, Train Loss: 1.8089723205318324e-06\n",
      "Epoch: 10, Validation Loss: 1.1072667941055177e-06\n",
      "Epoch: 11, Train Loss: 1.6625423466798755e-06\n",
      "Epoch: 11, Validation Loss: 6.911457607634049e-07\n",
      "Epoch: 12, Train Loss: 1.5760691064929643e-06\n",
      "Epoch: 12, Validation Loss: 6.2390859014753605e-06\n",
      "Epoch: 13, Train Loss: 1.5013577453350363e-06\n",
      "Epoch: 13, Validation Loss: 3.516776103845678e-06\n",
      "At temperature 15 the loss is 0.0008135224975541354\n",
      "At temperature 25 the loss is 0.0007823592730187755\n",
      "At temperature 45 the loss is 0.0007528822861321383\n",
      "At temperature 15 the loss is 0.0008871316884752184\n",
      "At temperature 25 the loss is 0.0008279734796984527\n",
      "At temperature 45 the loss is 0.0007592622193191472\n",
      "Number of no improvement trials is 3\n",
      "Trial 8/100 completed. Remaining trials: 92\n",
      "Trial parameters\n",
      "{'num_layers': 2, 'num_neurons': 167, 'sequence_length': 10, 'batch_size': 256, 'epochs': 37, 'lr': 0.009159486752977172}\n",
      "Epoch: 1, Train Loss: 0.007281950582892833\n",
      "Epoch: 1, Validation Loss: 4.611293146480945e-05\n",
      "Epoch: 2, Train Loss: 8.579738206568548e-05\n",
      "Epoch: 2, Validation Loss: 7.574676780320965e-05\n",
      "Epoch: 3, Train Loss: 6.764291828179726e-05\n",
      "Epoch: 3, Validation Loss: 2.9713876572604804e-05\n",
      "Epoch: 4, Train Loss: 4.419172952898895e-05\n",
      "Epoch: 4, Validation Loss: 1.3199641106577423e-05\n",
      "Epoch: 5, Train Loss: 3.331740183410099e-05\n",
      "Epoch: 5, Validation Loss: 5.216619236937349e-05\n",
      "Epoch: 6, Train Loss: 2.704437251833796e-05\n",
      "Epoch: 6, Validation Loss: 3.594294247200405e-05\n",
      "Epoch: 7, Train Loss: 2.1716649057746084e-05\n",
      "Epoch: 7, Validation Loss: 1.1258076475144408e-05\n",
      "Epoch: 8, Train Loss: 1.7564616120188244e-05\n",
      "Epoch: 8, Validation Loss: 2.9106426682473005e-06\n",
      "Epoch: 9, Train Loss: 1.5248034373725761e-05\n",
      "Epoch: 9, Validation Loss: 6.712396331843114e-05\n",
      "Epoch: 10, Train Loss: 1.3934810236758016e-05\n",
      "Epoch: 10, Validation Loss: 5.528164150386365e-06\n",
      "Epoch: 11, Train Loss: 1.4182712516809242e-05\n",
      "Epoch: 11, Validation Loss: 2.2661620751794597e-05\n",
      "Epoch: 12, Train Loss: 1.372624319773417e-05\n",
      "Epoch: 12, Validation Loss: 2.069070549932096e-05\n",
      "Epoch: 13, Train Loss: 1.2626222065419019e-05\n",
      "Epoch: 13, Validation Loss: 0.0001229686672273158\n",
      "Epoch: 14, Train Loss: 1.2955886920251023e-05\n",
      "Epoch: 14, Validation Loss: 4.24253879088864e-05\n",
      "Epoch: 15, Train Loss: 1.3135470125929514e-05\n",
      "Epoch: 15, Validation Loss: 1.4993767021394233e-06\n",
      "Epoch: 16, Train Loss: 1.270043070492588e-05\n",
      "Epoch: 16, Validation Loss: 1.55907599197852e-05\n",
      "Epoch: 17, Train Loss: 1.2575113889470738e-05\n",
      "Epoch: 17, Validation Loss: 1.8774446637061222e-06\n",
      "Epoch: 18, Train Loss: 1.157466202983545e-05\n",
      "Epoch: 18, Validation Loss: 4.302664921543308e-06\n",
      "Epoch: 19, Train Loss: 1.1683979672586105e-05\n",
      "Epoch: 19, Validation Loss: 7.878998633138954e-06\n",
      "Epoch: 20, Train Loss: 1.1053959307815985e-05\n",
      "Epoch: 20, Validation Loss: 3.7200908546402123e-06\n",
      "Epoch: 21, Train Loss: 1.0711446546694681e-05\n",
      "Epoch: 21, Validation Loss: 6.522232801114047e-06\n",
      "Epoch: 22, Train Loss: 1.0813444476101649e-05\n",
      "Epoch: 22, Validation Loss: 2.132028606698672e-05\n",
      "Epoch: 23, Train Loss: 1.0659909059293332e-05\n",
      "Epoch: 23, Validation Loss: 2.0190174166186052e-05\n",
      "Epoch: 24, Train Loss: 1.0178943756421114e-05\n",
      "Epoch: 24, Validation Loss: 3.7839270328638602e-06\n",
      "Epoch: 25, Train Loss: 1.0500894863323729e-05\n",
      "Epoch: 25, Validation Loss: 6.7162325077356155e-06\n",
      "Epoch: 26, Train Loss: 1.0106210220848537e-05\n",
      "Epoch: 26, Validation Loss: 2.6025734366700973e-05\n",
      "Epoch: 27, Train Loss: 1.0146767920122264e-05\n",
      "Epoch: 27, Validation Loss: 5.301084333645404e-06\n",
      "Epoch: 28, Train Loss: 1.0553246350721095e-05\n",
      "Epoch: 28, Validation Loss: 1.055490840127685e-05\n",
      "Epoch: 29, Train Loss: 1.0144408023325813e-05\n",
      "Epoch: 29, Validation Loss: 2.082796696371646e-06\n",
      "Epoch: 30, Train Loss: 9.662031858861425e-06\n",
      "Epoch: 30, Validation Loss: 5.804359992805008e-06\n",
      "Epoch: 31, Train Loss: 9.52298936913391e-06\n",
      "Epoch: 31, Validation Loss: 7.027773101759689e-06\n",
      "Epoch: 32, Train Loss: 9.630981711206159e-06\n",
      "Epoch: 32, Validation Loss: 2.3790646117840203e-06\n",
      "Epoch: 33, Train Loss: 9.089368240751386e-06\n",
      "Epoch: 33, Validation Loss: 8.298105006139106e-06\n",
      "Epoch: 34, Train Loss: 1.0040200443092444e-05\n",
      "Epoch: 34, Validation Loss: 1.6710448241607505e-05\n",
      "Epoch: 35, Train Loss: 9.863595824953298e-06\n",
      "Epoch: 35, Validation Loss: 4.3158160682227e-06\n",
      "Epoch: 36, Train Loss: 9.071503008883998e-06\n",
      "Epoch: 36, Validation Loss: 5.562087014686607e-06\n",
      "Epoch: 37, Train Loss: 8.507803188266637e-06\n",
      "Epoch: 37, Validation Loss: 3.6454203431173417e-06\n",
      "At temperature 15 the loss is 0.0007901996230345482\n",
      "At temperature 25 the loss is 0.0007645862534382316\n",
      "At temperature 45 the loss is 0.0007821589303437742\n",
      "At temperature 15 the loss is 0.000923228830965114\n",
      "At temperature 25 the loss is 0.0008558302133361542\n",
      "At temperature 45 the loss is 0.0007574727091175439\n",
      "Number of no improvement trials is 4\n",
      "Trial 9/100 completed. Remaining trials: 91\n",
      "Trial parameters\n",
      "{'num_layers': 1, 'num_neurons': 225, 'sequence_length': 4, 'batch_size': 256, 'epochs': 42, 'lr': 0.0020842191767191038}\n",
      "Epoch: 1, Train Loss: 0.0009612017664658587\n",
      "Epoch: 1, Validation Loss: 7.0377338004518525e-06\n",
      "Epoch: 2, Train Loss: 3.685563739999195e-05\n",
      "Epoch: 2, Validation Loss: 3.529240036463456e-05\n",
      "Epoch: 3, Train Loss: 2.1593621753730066e-05\n",
      "Epoch: 3, Validation Loss: 1.1883470154559715e-05\n",
      "Epoch: 4, Train Loss: 1.2378882193495028e-05\n",
      "Epoch: 4, Validation Loss: 6.137619166188129e-06\n",
      "Epoch: 5, Train Loss: 9.508864360632147e-06\n",
      "Epoch: 5, Validation Loss: 9.116218412034466e-06\n",
      "Epoch: 6, Train Loss: 7.313576479706667e-06\n",
      "Epoch: 6, Validation Loss: 3.1631030268442708e-06\n",
      "Epoch: 7, Train Loss: 5.349524747104638e-06\n",
      "Epoch: 7, Validation Loss: 7.304645922698205e-06\n",
      "Epoch: 8, Train Loss: 4.811637612770011e-06\n",
      "Epoch: 8, Validation Loss: 2.0203971571140546e-05\n",
      "Epoch: 9, Train Loss: 4.341741564571055e-06\n",
      "Epoch: 9, Validation Loss: 1.9673301281938145e-06\n",
      "Epoch: 10, Train Loss: 3.779251242925621e-06\n",
      "Epoch: 10, Validation Loss: 1.8961139011786715e-06\n",
      "Epoch: 11, Train Loss: 3.3821780331834257e-06\n",
      "Epoch: 11, Validation Loss: 1.3209624233694365e-06\n",
      "Epoch: 12, Train Loss: 3.337564504209066e-06\n",
      "Epoch: 12, Validation Loss: 2.1395714102748936e-06\n",
      "Epoch: 13, Train Loss: 2.867278844159094e-06\n",
      "Epoch: 13, Validation Loss: 1.8059879040399017e-06\n",
      "Epoch: 14, Train Loss: 2.8067834423085587e-06\n",
      "Epoch: 14, Validation Loss: 1.358591796726849e-06\n",
      "Epoch: 15, Train Loss: 2.9261566933224197e-06\n",
      "Epoch: 15, Validation Loss: 3.994957266681187e-06\n",
      "Epoch: 16, Train Loss: 2.393078055610516e-06\n",
      "Epoch: 16, Validation Loss: 1.4632109183969044e-06\n",
      "Epoch: 17, Train Loss: 2.3101245939281942e-06\n",
      "Epoch: 17, Validation Loss: 7.615994619671168e-07\n",
      "Epoch: 18, Train Loss: 2.37285346813531e-06\n",
      "Epoch: 18, Validation Loss: 9.170155470534398e-07\n",
      "Epoch: 19, Train Loss: 2.107220316384413e-06\n",
      "Epoch: 19, Validation Loss: 1.803311208942543e-06\n",
      "Epoch: 20, Train Loss: 2.057560858569195e-06\n",
      "Epoch: 20, Validation Loss: 4.043893323907549e-06\n",
      "Epoch: 21, Train Loss: 1.9826224338796507e-06\n",
      "Epoch: 21, Validation Loss: 7.969080739592784e-07\n",
      "Epoch: 22, Train Loss: 1.823074151791896e-06\n",
      "Epoch: 22, Validation Loss: 1.0103638463325293e-06\n",
      "Epoch: 23, Train Loss: 1.7489648175274892e-06\n",
      "Epoch: 23, Validation Loss: 1.4304685914848948e-06\n",
      "Epoch: 24, Train Loss: 1.7658542274341465e-06\n",
      "Epoch: 24, Validation Loss: 6.937097225746162e-07\n",
      "Epoch: 25, Train Loss: 1.651155555020407e-06\n",
      "Epoch: 25, Validation Loss: 1.1057769716496765e-06\n",
      "Epoch: 26, Train Loss: 1.7405759201996707e-06\n",
      "Epoch: 26, Validation Loss: 1.0505381535676283e-06\n",
      "Epoch: 27, Train Loss: 1.5300162676606812e-06\n",
      "Epoch: 27, Validation Loss: 8.086834250573027e-07\n",
      "Epoch: 28, Train Loss: 1.5699260135420926e-06\n",
      "Epoch: 28, Validation Loss: 9.369410715241628e-07\n",
      "Epoch: 29, Train Loss: 1.5945241863727072e-06\n",
      "Epoch: 29, Validation Loss: 1.0234258750135068e-06\n",
      "Epoch: 30, Train Loss: 1.4893592860492325e-06\n",
      "Epoch: 30, Validation Loss: 2.658521554651509e-06\n",
      "Epoch: 31, Train Loss: 1.5038552969873278e-06\n",
      "Epoch: 31, Validation Loss: 2.667401579470483e-06\n",
      "Epoch: 32, Train Loss: 1.5546811181826938e-06\n",
      "Epoch: 32, Validation Loss: 8.252063789348318e-07\n",
      "Epoch: 33, Train Loss: 1.4121435848601644e-06\n",
      "Epoch: 33, Validation Loss: 8.546539483249071e-07\n",
      "Epoch: 34, Train Loss: 1.3928111728160247e-06\n",
      "Epoch: 34, Validation Loss: 1.8245920463155558e-06\n",
      "Epoch: 35, Train Loss: 1.4269906429788296e-06\n",
      "Epoch: 35, Validation Loss: 5.132116247853208e-07\n",
      "Epoch: 36, Train Loss: 1.3806342842723548e-06\n",
      "Epoch: 36, Validation Loss: 5.979180185835311e-07\n",
      "Epoch: 37, Train Loss: 1.3306884201217738e-06\n",
      "Epoch: 37, Validation Loss: 9.471469271274329e-07\n",
      "Epoch: 38, Train Loss: 1.4293135853808174e-06\n",
      "Epoch: 38, Validation Loss: 1.4491749157630771e-06\n",
      "Epoch: 39, Train Loss: 1.269014710482867e-06\n",
      "Epoch: 39, Validation Loss: 1.1463153367930366e-06\n",
      "Epoch: 40, Train Loss: 1.4202130073828325e-06\n",
      "Epoch: 40, Validation Loss: 9.474717502798907e-07\n",
      "Epoch: 41, Train Loss: 1.2870576102913585e-06\n",
      "Epoch: 41, Validation Loss: 7.166247685457607e-07\n",
      "Epoch: 42, Train Loss: 1.3042681980490174e-06\n",
      "Epoch: 42, Validation Loss: 5.65895101800105e-07\n",
      "At temperature 15 the loss is 0.0008268761913673505\n",
      "At temperature 25 the loss is 0.0008073822211774187\n",
      "At temperature 45 the loss is 0.0007935877371313505\n",
      "At temperature 15 the loss is 0.0008679108882355395\n",
      "At temperature 25 the loss is 0.0007960095745782087\n",
      "At temperature 45 the loss is 0.0007418624762852811\n",
      "Number of no improvement trials is 5\n",
      "Trial 10/100 completed. Remaining trials: 90\n",
      "Trial parameters\n",
      "{'num_layers': 4, 'num_neurons': 109, 'sequence_length': 1, 'batch_size': 32, 'epochs': 47, 'lr': 0.00010450315433317432}\n",
      "Epoch: 1, Train Loss: 0.001773539600815816\n",
      "Epoch: 1, Validation Loss: 3.709070388420095e-05\n",
      "Epoch: 2, Train Loss: 1.3982828183619253e-05\n",
      "Epoch: 2, Validation Loss: 5.523076660739825e-06\n",
      "Epoch: 3, Train Loss: 9.872115602394637e-06\n",
      "Epoch: 3, Validation Loss: 7.972530239142565e-06\n",
      "Epoch: 4, Train Loss: 6.984194183135149e-06\n",
      "Epoch: 4, Validation Loss: 7.031007866929687e-06\n",
      "Epoch: 5, Train Loss: 5.63434974123926e-06\n",
      "Epoch: 5, Validation Loss: 1.7760585044947349e-06\n",
      "Epoch: 6, Train Loss: 5.136684595356376e-06\n",
      "Epoch: 6, Validation Loss: 1.8562855827686438e-06\n",
      "Epoch: 7, Train Loss: 3.95590223126023e-06\n",
      "Epoch: 7, Validation Loss: 1.9932089599835084e-06\n",
      "Epoch: 8, Train Loss: 3.213678671183772e-06\n",
      "Epoch: 8, Validation Loss: 6.550076191389346e-06\n",
      "Epoch: 9, Train Loss: 2.8754755584538067e-06\n",
      "Epoch: 9, Validation Loss: 3.4153815955017275e-06\n",
      "Epoch: 10, Train Loss: 2.4263296685808207e-06\n",
      "Epoch: 10, Validation Loss: 8.24678257134331e-06\n",
      "Epoch: 11, Train Loss: 2.3837834669242573e-06\n",
      "Epoch: 11, Validation Loss: 1.883362122148528e-06\n",
      "Epoch: 12, Train Loss: 2.161154501777437e-06\n",
      "Epoch: 12, Validation Loss: 8.255787979642761e-07\n",
      "Epoch: 13, Train Loss: 1.9608387335948324e-06\n",
      "Epoch: 13, Validation Loss: 1.7508616311724564e-06\n",
      "Epoch: 14, Train Loss: 1.8863993245944445e-06\n",
      "Epoch: 14, Validation Loss: 1.4029512103493121e-06\n",
      "Epoch: 15, Train Loss: 1.8204617415476388e-06\n",
      "Epoch: 15, Validation Loss: 9.419550466188434e-07\n",
      "Epoch: 16, Train Loss: 1.592168765309483e-06\n",
      "Epoch: 16, Validation Loss: 7.197111203395637e-07\n",
      "Epoch: 17, Train Loss: 1.5572751325663668e-06\n",
      "Epoch: 17, Validation Loss: 7.060469713534522e-07\n",
      "Epoch: 18, Train Loss: 1.4567686816939148e-06\n",
      "Epoch: 18, Validation Loss: 2.113471866694416e-06\n",
      "Epoch: 19, Train Loss: 1.3976074491567686e-06\n",
      "Epoch: 19, Validation Loss: 7.020954021755234e-07\n",
      "Epoch: 20, Train Loss: 1.3166642202773532e-06\n",
      "Epoch: 20, Validation Loss: 7.188038881192726e-07\n",
      "Epoch: 21, Train Loss: 1.2373110684962304e-06\n",
      "Epoch: 21, Validation Loss: 4.206215793054907e-06\n",
      "Epoch: 22, Train Loss: 1.243041564887942e-06\n",
      "Epoch: 22, Validation Loss: 4.05858088544831e-07\n",
      "Epoch: 23, Train Loss: 1.2345326773592507e-06\n",
      "Epoch: 23, Validation Loss: 6.454291754871532e-07\n",
      "Epoch: 24, Train Loss: 1.1481977236654712e-06\n",
      "Epoch: 24, Validation Loss: 6.966742728576251e-07\n",
      "Epoch: 25, Train Loss: 1.1343244286368296e-06\n",
      "Epoch: 25, Validation Loss: 6.148706283970032e-06\n",
      "Epoch: 26, Train Loss: 1.0561632286022493e-06\n",
      "Epoch: 26, Validation Loss: 6.722207577788156e-07\n",
      "Epoch: 27, Train Loss: 9.981698118137675e-07\n",
      "Epoch: 27, Validation Loss: 1.989758035722128e-06\n",
      "Epoch: 28, Train Loss: 1.0262240998675357e-06\n",
      "Epoch: 28, Validation Loss: 6.536992567111845e-07\n",
      "Epoch: 29, Train Loss: 9.298513911210417e-07\n",
      "Epoch: 29, Validation Loss: 8.825075116783731e-07\n",
      "Epoch: 30, Train Loss: 9.148703003078082e-07\n",
      "Epoch: 30, Validation Loss: 8.781846120128317e-06\n",
      "Epoch: 31, Train Loss: 8.425695338763123e-07\n",
      "Epoch: 31, Validation Loss: 1.387369729674526e-06\n",
      "Epoch: 32, Train Loss: 8.35704712803922e-07\n",
      "Epoch: 32, Validation Loss: 5.613588423140451e-07\n",
      "Epoch: 33, Train Loss: 8.498713560820259e-07\n",
      "Epoch: 33, Validation Loss: 3.7745223778228423e-06\n",
      "Epoch: 34, Train Loss: 8.326620636874727e-07\n",
      "Epoch: 34, Validation Loss: 3.692626771213879e-07\n",
      "Epoch: 35, Train Loss: 8.22447776526267e-07\n",
      "Epoch: 35, Validation Loss: 5.230157886897073e-07\n",
      "Epoch: 36, Train Loss: 7.778631876965658e-07\n",
      "Epoch: 36, Validation Loss: 5.615767534262059e-07\n",
      "Epoch: 37, Train Loss: 7.786514815002933e-07\n",
      "Epoch: 37, Validation Loss: 7.481845009051415e-07\n",
      "Epoch: 38, Train Loss: 7.045471753360544e-07\n",
      "Epoch: 38, Validation Loss: 7.051709149757858e-07\n",
      "Epoch: 39, Train Loss: 6.761336575709187e-07\n",
      "Epoch: 39, Validation Loss: 8.00006186702157e-07\n",
      "Epoch: 40, Train Loss: 6.596780897694429e-07\n",
      "Epoch: 40, Validation Loss: 3.4283007436976404e-07\n",
      "Epoch: 41, Train Loss: 6.780170474272523e-07\n",
      "Epoch: 41, Validation Loss: 1.10174412216193e-06\n",
      "Epoch: 42, Train Loss: 6.866139330101724e-07\n",
      "Epoch: 42, Validation Loss: 4.908655523822877e-07\n",
      "Epoch: 43, Train Loss: 6.308464227765586e-07\n",
      "Epoch: 43, Validation Loss: 8.898528513094431e-07\n",
      "Epoch: 44, Train Loss: 5.806962125287842e-07\n",
      "Epoch: 44, Validation Loss: 2.615862068491304e-07\n",
      "Epoch: 45, Train Loss: 5.909633695113855e-07\n",
      "Epoch: 45, Validation Loss: 3.931313667311733e-07\n",
      "Epoch: 46, Train Loss: 5.969716729240558e-07\n",
      "Epoch: 46, Validation Loss: 2.713836933020696e-07\n",
      "Epoch: 47, Train Loss: 5.826734329833683e-07\n",
      "Epoch: 47, Validation Loss: 6.58515038855245e-07\n",
      "At temperature 15 the loss is 0.0008734982249772129\n",
      "At temperature 25 the loss is 0.0008542470749790842\n",
      "At temperature 45 the loss is 0.0007953039964676959\n",
      "At temperature 15 the loss is 0.0008122860806753905\n",
      "At temperature 25 the loss is 0.0007905349646053702\n",
      "At temperature 45 the loss is 0.0006978381555788944\n",
      "Number of no improvement trials is 6\n",
      "Trial 11/100 completed. Remaining trials: 89\n",
      "Trial parameters\n",
      "{'num_layers': 4, 'num_neurons': 98, 'sequence_length': 1, 'batch_size': 32, 'epochs': 24, 'lr': 0.00010015355883120207}\n",
      "Epoch: 1, Train Loss: 0.002866941737904129\n",
      "Epoch: 1, Validation Loss: 8.338982262564911e-06\n",
      "Epoch: 2, Train Loss: 1.0001644769969393e-05\n",
      "Epoch: 2, Validation Loss: 3.374531319350129e-06\n",
      "Epoch: 3, Train Loss: 7.63445471369516e-06\n",
      "Epoch: 3, Validation Loss: 2.3199663040116352e-06\n",
      "Epoch: 4, Train Loss: 6.4156735933112995e-06\n",
      "Epoch: 4, Validation Loss: 1.885603052741332e-06\n",
      "Epoch: 5, Train Loss: 5.657270500108586e-06\n",
      "Epoch: 5, Validation Loss: 3.0480056450666483e-06\n",
      "Epoch: 6, Train Loss: 4.710717492445201e-06\n",
      "Epoch: 6, Validation Loss: 2.7628614020613894e-06\n",
      "Epoch: 7, Train Loss: 4.107181796324856e-06\n",
      "Epoch: 7, Validation Loss: 4.044547884032352e-06\n",
      "Epoch: 8, Train Loss: 3.6353613373966225e-06\n",
      "Epoch: 8, Validation Loss: 2.658402016499772e-06\n",
      "Epoch: 9, Train Loss: 3.504765205700781e-06\n",
      "Epoch: 9, Validation Loss: 1.325505219099333e-06\n",
      "Epoch: 10, Train Loss: 3.1451638873520446e-06\n",
      "Epoch: 10, Validation Loss: 1.4217016343280625e-06\n",
      "Epoch: 11, Train Loss: 2.8785756971818153e-06\n",
      "Epoch: 11, Validation Loss: 2.3489611540150964e-06\n",
      "Epoch: 12, Train Loss: 2.7109891539120735e-06\n",
      "Epoch: 12, Validation Loss: 2.3998506080134776e-06\n",
      "Epoch: 13, Train Loss: 2.719552498864101e-06\n",
      "Epoch: 13, Validation Loss: 1.1277855855620368e-06\n",
      "Epoch: 14, Train Loss: 2.3464634801447655e-06\n",
      "Epoch: 14, Validation Loss: 1.4672162354808331e-06\n",
      "Epoch: 15, Train Loss: 2.243723721746738e-06\n",
      "Epoch: 15, Validation Loss: 1.3306480900301762e-06\n",
      "Epoch: 16, Train Loss: 2.1895389030030414e-06\n",
      "Epoch: 16, Validation Loss: 1.4032511617094758e-06\n",
      "Epoch: 17, Train Loss: 2.032618570095273e-06\n",
      "Epoch: 17, Validation Loss: 1.685652643447404e-06\n",
      "Epoch: 18, Train Loss: 1.957456386359484e-06\n",
      "Epoch: 18, Validation Loss: 3.807411990782973e-06\n",
      "Epoch: 19, Train Loss: 1.8503858819604227e-06\n",
      "Epoch: 19, Validation Loss: 8.220281707021118e-07\n",
      "Epoch: 20, Train Loss: 1.7890151049997442e-06\n",
      "Epoch: 20, Validation Loss: 3.2849916672912466e-06\n",
      "Epoch: 21, Train Loss: 1.7599310048646954e-06\n",
      "Epoch: 21, Validation Loss: 1.8335712500623984e-06\n",
      "Epoch: 22, Train Loss: 1.5782099106398368e-06\n",
      "Epoch: 22, Validation Loss: 9.66601336631196e-07\n",
      "Epoch: 23, Train Loss: 1.512264836982766e-06\n",
      "Epoch: 23, Validation Loss: 3.3735605292619526e-06\n",
      "Epoch: 24, Train Loss: 1.5091069572109642e-06\n",
      "Epoch: 24, Validation Loss: 4.868303091995539e-06\n",
      "At temperature 15 the loss is 0.0007983546095200992\n",
      "At temperature 25 the loss is 0.0007513849142103375\n",
      "At temperature 45 the loss is 0.0006792152182645788\n",
      "At temperature 15 the loss is 0.0008225460555837118\n",
      "At temperature 25 the loss is 0.0007933045838208907\n",
      "At temperature 45 the loss is 0.0007712525292118181\n",
      "Trial 12/100 completed. Remaining trials: 88\n",
      "Trial parameters\n",
      "{'num_layers': 5, 'num_neurons': 105, 'sequence_length': 1, 'batch_size': 128, 'epochs': 26, 'lr': 0.0002119532252080278}\n",
      "Epoch: 1, Train Loss: 0.0049255585256506185\n",
      "Epoch: 1, Validation Loss: 1.753609326963844e-05\n",
      "Epoch: 2, Train Loss: 1.7523464266656283e-05\n",
      "Epoch: 2, Validation Loss: 3.3615252231464335e-05\n",
      "Epoch: 3, Train Loss: 1.4382828865344784e-05\n",
      "Epoch: 3, Validation Loss: 4.659600777272902e-06\n",
      "Epoch: 4, Train Loss: 1.1434485929195383e-05\n",
      "Epoch: 4, Validation Loss: 6.95121567569934e-06\n",
      "Epoch: 5, Train Loss: 7.90793709582167e-06\n",
      "Epoch: 5, Validation Loss: 2.735557900787508e-06\n",
      "Epoch: 6, Train Loss: 6.420024957293628e-06\n",
      "Epoch: 6, Validation Loss: 5.044576270063377e-06\n",
      "Epoch: 7, Train Loss: 5.304895814777153e-06\n",
      "Epoch: 7, Validation Loss: 2.359607732854482e-06\n",
      "Epoch: 8, Train Loss: 4.77966291287515e-06\n",
      "Epoch: 8, Validation Loss: 1.5671467655452844e-06\n",
      "Epoch: 9, Train Loss: 4.057543111754024e-06\n",
      "Epoch: 9, Validation Loss: 3.940249124282895e-06\n",
      "Epoch: 10, Train Loss: 4.03569403203687e-06\n",
      "Epoch: 10, Validation Loss: 7.1100118182703695e-06\n",
      "Epoch: 11, Train Loss: 3.417149686538942e-06\n",
      "Epoch: 11, Validation Loss: 1.6558002574817342e-06\n",
      "Epoch: 12, Train Loss: 3.4091476308477892e-06\n",
      "Epoch: 12, Validation Loss: 9.794273431233139e-07\n",
      "Epoch: 13, Train Loss: 3.698285690251989e-06\n",
      "Epoch: 13, Validation Loss: 1.4356058428216218e-06\n",
      "Epoch: 14, Train Loss: 3.2988803287628007e-06\n",
      "Epoch: 14, Validation Loss: 4.515138070254815e-06\n",
      "Epoch: 15, Train Loss: 3.2086726880807954e-06\n",
      "Epoch: 15, Validation Loss: 3.3940714286679862e-06\n",
      "Epoch: 16, Train Loss: 3.1013326794687844e-06\n",
      "Epoch: 16, Validation Loss: 2.508726304678234e-06\n",
      "Epoch: 17, Train Loss: 2.9069132168831082e-06\n",
      "Epoch: 17, Validation Loss: 2.8174664162925278e-06\n",
      "Epoch: 18, Train Loss: 2.6420899000312672e-06\n",
      "Epoch: 18, Validation Loss: 8.293999309487498e-07\n",
      "Epoch: 19, Train Loss: 2.9022923707355996e-06\n",
      "Epoch: 19, Validation Loss: 1.1077211202821977e-06\n",
      "Epoch: 20, Train Loss: 2.519247740294135e-06\n",
      "Epoch: 20, Validation Loss: 2.942191581600708e-06\n",
      "Epoch: 21, Train Loss: 2.4426510719791184e-06\n",
      "Epoch: 21, Validation Loss: 1.0029577548788505e-06\n",
      "Epoch: 22, Train Loss: 2.3502648940466255e-06\n",
      "Epoch: 22, Validation Loss: 2.870724074385034e-06\n",
      "Epoch: 23, Train Loss: 2.3481512487017435e-06\n",
      "Epoch: 23, Validation Loss: 2.3373437404799876e-06\n",
      "Epoch: 24, Train Loss: 2.217753956349011e-06\n",
      "Epoch: 24, Validation Loss: 7.422527842586044e-07\n",
      "Epoch: 25, Train Loss: 2.1002578059468687e-06\n",
      "Epoch: 25, Validation Loss: 1.2449099960410038e-06\n",
      "Epoch: 26, Train Loss: 1.7939663399567695e-06\n",
      "Epoch: 26, Validation Loss: 1.0774696743427493e-06\n",
      "At temperature 15 the loss is 0.0008848590221639504\n",
      "At temperature 25 the loss is 0.0008264734901891897\n",
      "At temperature 45 the loss is 0.0008223452668144918\n",
      "At temperature 15 the loss is 0.0008530015252878964\n",
      "At temperature 25 the loss is 0.0007782781008615509\n",
      "At temperature 45 the loss is 0.0006947359431660255\n",
      "Number of no improvement trials is 1\n",
      "Trial 13/100 completed. Remaining trials: 87\n",
      "Trial parameters\n",
      "{'num_layers': 3, 'num_neurons': 89, 'sequence_length': 2, 'batch_size': 32, 'epochs': 50, 'lr': 0.00023510853758967762}\n",
      "Epoch: 1, Train Loss: 0.0004659304031875943\n",
      "Epoch: 1, Validation Loss: 1.533636607763529e-05\n",
      "Epoch: 2, Train Loss: 1.2730869058895692e-05\n",
      "Epoch: 2, Validation Loss: 5.116512258632053e-06\n",
      "Epoch: 3, Train Loss: 7.652140942701736e-06\n",
      "Epoch: 3, Validation Loss: 2.523288929405114e-06\n",
      "Epoch: 4, Train Loss: 4.520251487774104e-06\n",
      "Epoch: 4, Validation Loss: 3.506292820004379e-06\n",
      "Epoch: 5, Train Loss: 3.4311663976402784e-06\n",
      "Epoch: 5, Validation Loss: 1.067463498365966e-06\n",
      "Epoch: 6, Train Loss: 2.6141493108284283e-06\n",
      "Epoch: 6, Validation Loss: 1.7350410296443771e-06\n",
      "Epoch: 7, Train Loss: 2.4525104637161403e-06\n",
      "Epoch: 7, Validation Loss: 3.6757788093325304e-06\n",
      "Epoch: 8, Train Loss: 2.115567623711355e-06\n",
      "Epoch: 8, Validation Loss: 9.005713600595565e-07\n",
      "Epoch: 9, Train Loss: 1.8576109362514086e-06\n",
      "Epoch: 9, Validation Loss: 2.0992705606586286e-06\n",
      "Epoch: 10, Train Loss: 1.6233107039457324e-06\n",
      "Epoch: 10, Validation Loss: 7.427775058783899e-06\n",
      "Epoch: 11, Train Loss: 1.4302716595135422e-06\n",
      "Epoch: 11, Validation Loss: 1.187540125668043e-06\n",
      "Epoch: 12, Train Loss: 1.257740022477685e-06\n",
      "Epoch: 12, Validation Loss: 2.0318897120980745e-06\n",
      "Epoch: 13, Train Loss: 1.242236042732161e-06\n",
      "Epoch: 13, Validation Loss: 2.2777667780177394e-06\n",
      "Epoch: 14, Train Loss: 1.1581835617386809e-06\n",
      "Epoch: 14, Validation Loss: 8.096774713551662e-07\n",
      "Epoch: 15, Train Loss: 1.0862654516620746e-06\n",
      "Epoch: 15, Validation Loss: 4.5636614554727613e-07\n",
      "Epoch: 16, Train Loss: 1.0471858990656138e-06\n",
      "Epoch: 16, Validation Loss: 6.373178530928259e-07\n",
      "Epoch: 17, Train Loss: 9.402898625935805e-07\n",
      "Epoch: 17, Validation Loss: 7.236357713577763e-07\n",
      "Epoch: 18, Train Loss: 9.04477120994234e-07\n",
      "Epoch: 18, Validation Loss: 7.025240023696711e-07\n",
      "Epoch: 19, Train Loss: 9.19642746507514e-07\n",
      "Epoch: 19, Validation Loss: 4.4830386086620833e-07\n",
      "Epoch: 20, Train Loss: 8.395863726214244e-07\n",
      "Epoch: 20, Validation Loss: 2.8304761820947053e-07\n",
      "Epoch: 21, Train Loss: 8.154218379506732e-07\n",
      "Epoch: 21, Validation Loss: 3.98789475541321e-07\n",
      "Epoch: 22, Train Loss: 7.661873020919191e-07\n",
      "Epoch: 22, Validation Loss: 5.039526815160294e-07\n",
      "Epoch: 23, Train Loss: 7.194522419197266e-07\n",
      "Epoch: 23, Validation Loss: 3.730649383168854e-07\n",
      "Epoch: 24, Train Loss: 6.92762574739847e-07\n",
      "Epoch: 24, Validation Loss: 3.6798924334153216e-07\n",
      "Epoch: 25, Train Loss: 6.681385537226253e-07\n",
      "Epoch: 25, Validation Loss: 4.1094106460320736e-07\n",
      "Epoch: 26, Train Loss: 6.591371494666989e-07\n",
      "Epoch: 26, Validation Loss: 3.6057306526076296e-07\n",
      "Epoch: 27, Train Loss: 5.851203709735015e-07\n",
      "Epoch: 27, Validation Loss: 3.811083185384498e-07\n",
      "Epoch: 28, Train Loss: 5.985022970526821e-07\n",
      "Epoch: 28, Validation Loss: 4.1920575462522923e-07\n",
      "Epoch: 29, Train Loss: 5.700986741380397e-07\n",
      "Epoch: 29, Validation Loss: 5.028280742430793e-07\n",
      "Epoch: 30, Train Loss: 5.848657698290201e-07\n",
      "Epoch: 30, Validation Loss: 2.3397417987773732e-07\n",
      "Epoch: 31, Train Loss: 5.528639077478773e-07\n",
      "Epoch: 31, Validation Loss: 6.444964065808891e-07\n",
      "Epoch: 32, Train Loss: 5.302936587744449e-07\n",
      "Epoch: 32, Validation Loss: 4.5755011869400006e-07\n",
      "Epoch: 33, Train Loss: 5.448189111514876e-07\n",
      "Epoch: 33, Validation Loss: 3.002059868706486e-07\n",
      "Epoch: 34, Train Loss: 5.143212862325843e-07\n",
      "Epoch: 34, Validation Loss: 3.4429405238285127e-07\n",
      "Epoch: 35, Train Loss: 5.338822062387529e-07\n",
      "Epoch: 35, Validation Loss: 4.092861416073644e-07\n",
      "Epoch: 36, Train Loss: 5.096710109161634e-07\n",
      "Epoch: 36, Validation Loss: 3.6094524567696024e-07\n",
      "Epoch: 37, Train Loss: 4.938973894128291e-07\n",
      "Epoch: 37, Validation Loss: 7.105657750468915e-07\n",
      "Epoch: 38, Train Loss: 4.856564035344296e-07\n",
      "Epoch: 38, Validation Loss: 3.7915511354437984e-07\n",
      "Epoch: 39, Train Loss: 4.7585513532943087e-07\n",
      "Epoch: 39, Validation Loss: 3.950733054568216e-07\n",
      "Epoch: 40, Train Loss: 4.769529456993126e-07\n",
      "Epoch: 40, Validation Loss: 2.8635707612374597e-07\n",
      "Epoch: 41, Train Loss: 4.5479484296690876e-07\n",
      "Epoch: 41, Validation Loss: 3.898320041246717e-07\n",
      "Epoch: 42, Train Loss: 4.6215504079473095e-07\n",
      "Epoch: 42, Validation Loss: 2.2381626228002435e-07\n",
      "Epoch: 43, Train Loss: 4.4178061724579746e-07\n",
      "Epoch: 43, Validation Loss: 3.366404816616589e-07\n",
      "Epoch: 44, Train Loss: 4.5080512071934747e-07\n",
      "Epoch: 44, Validation Loss: 2.3727700892243425e-07\n",
      "Epoch: 45, Train Loss: 4.3519141630802265e-07\n",
      "Epoch: 45, Validation Loss: 3.212704040155257e-07\n",
      "Epoch: 46, Train Loss: 4.2843867501457416e-07\n",
      "Epoch: 46, Validation Loss: 2.745683430429069e-07\n",
      "Epoch: 47, Train Loss: 4.2490958386070896e-07\n",
      "Epoch: 47, Validation Loss: 2.1331948104971822e-07\n",
      "Epoch: 48, Train Loss: 4.0906111096506756e-07\n",
      "Epoch: 48, Validation Loss: 2.5255867371013717e-06\n",
      "Epoch: 49, Train Loss: 4.153749397361848e-07\n",
      "Epoch: 49, Validation Loss: 3.206752186093499e-06\n",
      "Epoch: 50, Train Loss: 4.0236331149732735e-07\n",
      "Epoch: 50, Validation Loss: 2.4133455027945464e-07\n",
      "At temperature 15 the loss is 0.0008289242158599665\n",
      "At temperature 25 the loss is 0.0007967185898030758\n",
      "At temperature 45 the loss is 0.0007767747228513144\n",
      "At temperature 15 the loss is 0.0008490939990626864\n",
      "At temperature 25 the loss is 0.0007926426238808807\n",
      "At temperature 45 the loss is 0.0007239025937394998\n",
      "Number of no improvement trials is 2\n",
      "Trial 14/100 completed. Remaining trials: 86\n",
      "Trial parameters\n",
      "{'num_layers': 4, 'num_neurons': 256, 'sequence_length': 2, 'batch_size': 32, 'epochs': 27, 'lr': 0.00010348563393111262}\n",
      "Epoch: 1, Train Loss: 0.00044429760959541556\n",
      "Epoch: 1, Validation Loss: 1.070849754559735e-05\n",
      "Epoch: 2, Train Loss: 1.9915234993344064e-05\n",
      "Epoch: 2, Validation Loss: 8.485556491806794e-06\n",
      "Epoch: 3, Train Loss: 1.0225929665064164e-05\n",
      "Epoch: 3, Validation Loss: 1.6589212356510602e-06\n",
      "Epoch: 4, Train Loss: 7.037615942739025e-06\n",
      "Epoch: 4, Validation Loss: 2.269148813640847e-06\n",
      "Epoch: 5, Train Loss: 4.946614848461126e-06\n",
      "Epoch: 5, Validation Loss: 2.546072260599093e-06\n",
      "Epoch: 6, Train Loss: 3.633159881228978e-06\n",
      "Epoch: 6, Validation Loss: 1.6599944772337669e-06\n",
      "Epoch: 7, Train Loss: 3.027781533035983e-06\n",
      "Epoch: 7, Validation Loss: 1.528121859604989e-06\n",
      "Epoch: 8, Train Loss: 2.247027734390865e-06\n",
      "Epoch: 8, Validation Loss: 1.6443738503851904e-06\n",
      "Epoch: 9, Train Loss: 2.3429012983707386e-06\n",
      "Epoch: 9, Validation Loss: 7.355919509766994e-07\n",
      "Epoch: 10, Train Loss: 1.9426535189435585e-06\n",
      "Epoch: 10, Validation Loss: 5.86257608075397e-07\n",
      "Epoch: 11, Train Loss: 1.7539500356620545e-06\n",
      "Epoch: 11, Validation Loss: 2.6109629471968903e-06\n",
      "Epoch: 12, Train Loss: 1.4084358906137557e-06\n",
      "Epoch: 12, Validation Loss: 5.497437728574553e-06\n",
      "Epoch: 13, Train Loss: 1.3626314251079332e-06\n",
      "Epoch: 13, Validation Loss: 7.856726697741686e-07\n",
      "Epoch: 14, Train Loss: 1.3000313635896584e-06\n",
      "Epoch: 14, Validation Loss: 6.639195842451132e-07\n",
      "Epoch: 15, Train Loss: 1.2005829084852974e-06\n",
      "Epoch: 15, Validation Loss: 1.190998557223174e-06\n",
      "Epoch: 16, Train Loss: 1.1204557687572595e-06\n",
      "Epoch: 16, Validation Loss: 3.024353294651857e-07\n",
      "Epoch: 17, Train Loss: 1.0502423231206006e-06\n",
      "Epoch: 17, Validation Loss: 4.042701246968177e-07\n",
      "Epoch: 18, Train Loss: 1.0345303342616355e-06\n",
      "Epoch: 18, Validation Loss: 2.982554242557892e-07\n",
      "Epoch: 19, Train Loss: 9.652487587234808e-07\n",
      "Epoch: 19, Validation Loss: 3.762553151103515e-07\n",
      "Epoch: 20, Train Loss: 8.773358352770576e-07\n",
      "Epoch: 20, Validation Loss: 9.55759478675712e-07\n",
      "Epoch: 21, Train Loss: 9.327039539836539e-07\n",
      "Epoch: 21, Validation Loss: 4.035464819287974e-07\n",
      "Epoch: 22, Train Loss: 8.256828144896708e-07\n",
      "Epoch: 22, Validation Loss: 3.007569218236648e-07\n",
      "Epoch: 23, Train Loss: 7.694253547052558e-07\n",
      "Epoch: 23, Validation Loss: 4.79201077336125e-07\n",
      "Epoch: 24, Train Loss: 7.577517604426155e-07\n",
      "Epoch: 24, Validation Loss: 1.7809801883549054e-06\n",
      "Epoch: 25, Train Loss: 7.400900178100643e-07\n",
      "Epoch: 25, Validation Loss: 2.092873007211199e-07\n",
      "Epoch: 26, Train Loss: 7.483549638835646e-07\n",
      "Epoch: 26, Validation Loss: 8.448305484570624e-07\n",
      "Epoch: 27, Train Loss: 6.904056820956065e-07\n",
      "Epoch: 27, Validation Loss: 3.98894378291025e-07\n",
      "At temperature 15 the loss is 0.0008437158117850721\n",
      "At temperature 25 the loss is 0.0008173378649303231\n",
      "At temperature 45 the loss is 0.0008060092851151653\n",
      "At temperature 15 the loss is 0.0008156337536846794\n",
      "At temperature 25 the loss is 0.0007795876214337367\n",
      "At temperature 45 the loss is 0.0007171534124637896\n",
      "Number of no improvement trials is 3\n",
      "Trial 15/100 completed. Remaining trials: 85\n",
      "Trial parameters\n",
      "{'num_layers': 5, 'num_neurons': 133, 'sequence_length': 3, 'batch_size': 32, 'epochs': 21, 'lr': 0.0003843050119518544}\n",
      "Epoch: 1, Train Loss: 0.00033254859575326736\n",
      "Epoch: 1, Validation Loss: 1.639820847778839e-05\n",
      "Epoch: 2, Train Loss: 1.1485279070853436e-05\n",
      "Epoch: 2, Validation Loss: 5.247967558707817e-06\n",
      "Epoch: 3, Train Loss: 6.212038157485306e-06\n",
      "Epoch: 3, Validation Loss: 1.2753104040353237e-06\n",
      "Epoch: 4, Train Loss: 4.031757000004559e-06\n",
      "Epoch: 4, Validation Loss: 1.931766663637289e-06\n",
      "Epoch: 5, Train Loss: 3.081020165443944e-06\n",
      "Epoch: 5, Validation Loss: 3.7886166660395896e-06\n",
      "Epoch: 6, Train Loss: 2.635024885777005e-06\n",
      "Epoch: 6, Validation Loss: 4.1686319144268025e-07\n",
      "Epoch: 7, Train Loss: 2.284778616090612e-06\n",
      "Epoch: 7, Validation Loss: 1.9852353974027816e-06\n",
      "Epoch: 8, Train Loss: 2.0538293911254906e-06\n",
      "Epoch: 8, Validation Loss: 4.347011875479128e-07\n",
      "Epoch: 9, Train Loss: 1.7530092405022565e-06\n",
      "Epoch: 9, Validation Loss: 2.293053762196405e-06\n",
      "Epoch: 10, Train Loss: 1.5921251861322372e-06\n",
      "Epoch: 10, Validation Loss: 1.6096692189783207e-06\n",
      "Epoch: 11, Train Loss: 1.4535736764809463e-06\n",
      "Epoch: 11, Validation Loss: 1.6263119544553716e-06\n",
      "Epoch: 12, Train Loss: 1.4161959183054925e-06\n",
      "Epoch: 12, Validation Loss: 3.9402812881713123e-07\n",
      "Epoch: 13, Train Loss: 1.3026459202058614e-06\n",
      "Epoch: 13, Validation Loss: 6.874838107831709e-07\n",
      "Epoch: 14, Train Loss: 1.2746321390623446e-06\n",
      "Epoch: 14, Validation Loss: 2.878626673525284e-07\n",
      "Epoch: 15, Train Loss: 1.222146887842769e-06\n",
      "Epoch: 15, Validation Loss: 1.4176690106163215e-06\n",
      "Epoch: 16, Train Loss: 1.1625700955887986e-06\n",
      "Epoch: 16, Validation Loss: 1.0702407822864683e-06\n",
      "Epoch: 17, Train Loss: 1.0982396164914452e-06\n",
      "Epoch: 17, Validation Loss: 2.7774759564417413e-06\n",
      "Epoch: 18, Train Loss: 1.0461028469779707e-06\n",
      "Epoch: 18, Validation Loss: 1.3320117326785504e-06\n",
      "Epoch: 19, Train Loss: 1.0599944392345829e-06\n",
      "Epoch: 19, Validation Loss: 1.7965585423676534e-06\n",
      "Epoch: 20, Train Loss: 1.0197414510724222e-06\n",
      "Epoch: 20, Validation Loss: 9.003717075599576e-07\n",
      "Epoch: 21, Train Loss: 9.933863655186974e-07\n",
      "Epoch: 21, Validation Loss: 2.022798441395234e-06\n",
      "At temperature 15 the loss is 0.0008847378361323961\n",
      "At temperature 25 the loss is 0.0008368675153019996\n",
      "At temperature 45 the loss is 0.0008067933274250291\n",
      "At temperature 15 the loss is 0.0007915617807297956\n",
      "At temperature 25 the loss is 0.0007520378795663345\n",
      "At temperature 45 the loss is 0.0007041649872200083\n",
      "Number of no improvement trials is 4\n",
      "Trial 16/100 completed. Remaining trials: 84\n",
      "Trial parameters\n",
      "{'num_layers': 4, 'num_neurons': 69, 'sequence_length': 1, 'batch_size': 128, 'epochs': 33, 'lr': 0.0001449136808612207}\n",
      "Epoch: 1, Train Loss: 0.0060308861150274035\n",
      "Epoch: 1, Validation Loss: 3.009492502218727e-05\n",
      "Epoch: 2, Train Loss: 2.1445714690231433e-05\n",
      "Epoch: 2, Validation Loss: 3.00402916866801e-05\n",
      "Epoch: 3, Train Loss: 1.5212329367747612e-05\n",
      "Epoch: 3, Validation Loss: 2.896631895616596e-05\n",
      "Epoch: 4, Train Loss: 1.2522004738286152e-05\n",
      "Epoch: 4, Validation Loss: 8.551531206009073e-06\n",
      "Epoch: 5, Train Loss: 1.0670044294005141e-05\n",
      "Epoch: 5, Validation Loss: 6.440436836895475e-06\n",
      "Epoch: 6, Train Loss: 9.805492314889068e-06\n",
      "Epoch: 6, Validation Loss: 1.398488834806981e-05\n",
      "Epoch: 7, Train Loss: 9.405565855385725e-06\n",
      "Epoch: 7, Validation Loss: 5.939951249131839e-06\n",
      "Epoch: 8, Train Loss: 8.434493745482866e-06\n",
      "Epoch: 8, Validation Loss: 2.36228974517711e-05\n",
      "Epoch: 9, Train Loss: 7.982785795738494e-06\n",
      "Epoch: 9, Validation Loss: 9.274254021214228e-06\n",
      "Epoch: 10, Train Loss: 8.125433234707917e-06\n",
      "Epoch: 10, Validation Loss: 4.454304758970815e-06\n",
      "Epoch: 11, Train Loss: 7.15843894415239e-06\n",
      "Epoch: 11, Validation Loss: 6.857295318862654e-06\n",
      "Epoch: 12, Train Loss: 7.253581251965483e-06\n",
      "Epoch: 12, Validation Loss: 4.460350486170575e-06\n",
      "Epoch: 13, Train Loss: 6.444897033743706e-06\n",
      "Epoch: 13, Validation Loss: 4.7610407271885435e-06\n",
      "Epoch: 14, Train Loss: 6.441834944369472e-06\n",
      "Epoch: 14, Validation Loss: 3.6601738664045577e-06\n",
      "Epoch: 15, Train Loss: 6.59310477452546e-06\n",
      "Epoch: 15, Validation Loss: 1.8388579796863516e-05\n",
      "Epoch: 16, Train Loss: 5.5798496439095585e-06\n",
      "Epoch: 16, Validation Loss: 1.878019712763181e-05\n",
      "Epoch: 17, Train Loss: 5.472236841599343e-06\n",
      "Epoch: 17, Validation Loss: 3.482735273415108e-06\n",
      "Epoch: 18, Train Loss: 5.870142399200696e-06\n",
      "Epoch: 18, Validation Loss: 9.656919672195365e-06\n",
      "Epoch: 19, Train Loss: 5.14554617308374e-06\n",
      "Epoch: 19, Validation Loss: 4.8149241215557595e-06\n",
      "Epoch: 20, Train Loss: 5.507321134048371e-06\n",
      "Epoch: 20, Validation Loss: 2.0454611784678224e-06\n",
      "Epoch: 21, Train Loss: 4.838672207291053e-06\n",
      "Epoch: 21, Validation Loss: 3.163338209363309e-06\n",
      "Epoch: 22, Train Loss: 4.3354300526077175e-06\n",
      "Epoch: 22, Validation Loss: 6.637634779176479e-06\n",
      "Epoch: 23, Train Loss: 4.601326193761718e-06\n",
      "Epoch: 23, Validation Loss: 2.6359747890297607e-06\n",
      "Epoch: 24, Train Loss: 4.219819119036459e-06\n",
      "Epoch: 24, Validation Loss: 6.564974579205821e-06\n",
      "Epoch: 25, Train Loss: 4.206637774548355e-06\n",
      "Epoch: 25, Validation Loss: 6.58061543685175e-06\n",
      "Epoch: 26, Train Loss: 4.045039915929776e-06\n",
      "Epoch: 26, Validation Loss: 3.002036038233713e-06\n",
      "Epoch: 27, Train Loss: 3.668216566111217e-06\n",
      "Epoch: 27, Validation Loss: 1.8536889915859323e-05\n",
      "Epoch: 28, Train Loss: 3.7107163362793797e-06\n",
      "Epoch: 28, Validation Loss: 4.955663863662456e-06\n",
      "Epoch: 29, Train Loss: 3.3498371313102036e-06\n",
      "Epoch: 29, Validation Loss: 1.5773690946758985e-06\n",
      "Epoch: 30, Train Loss: 3.107202552860368e-06\n",
      "Epoch: 30, Validation Loss: 3.4479747654709902e-06\n",
      "Epoch: 31, Train Loss: 3.075285244604868e-06\n",
      "Epoch: 31, Validation Loss: 1.7018937888451145e-06\n",
      "Epoch: 32, Train Loss: 2.7755400184979817e-06\n",
      "Epoch: 32, Validation Loss: 1.3196721413475356e-06\n",
      "Epoch: 33, Train Loss: 2.7543563994866003e-06\n",
      "Epoch: 33, Validation Loss: 1.5177684464239415e-06\n",
      "At temperature 15 the loss is 0.000786351558909861\n",
      "At temperature 25 the loss is 0.0008332068150223698\n",
      "At temperature 45 the loss is 0.0007957624344602333\n",
      "At temperature 15 the loss is 0.0008330469180424081\n",
      "At temperature 25 the loss is 0.000779080757871101\n",
      "At temperature 45 the loss is 0.0007443699099801297\n",
      "Number of no improvement trials is 5\n",
      "Trial 17/100 completed. Remaining trials: 83\n",
      "Trial parameters\n",
      "{'num_layers': 3, 'num_neurons': 142, 'sequence_length': 3, 'batch_size': 512, 'epochs': 41, 'lr': 0.00017500256486712332}\n",
      "Epoch: 1, Train Loss: 0.0042912663603112845\n",
      "Epoch: 1, Validation Loss: 2.894796222068111e-05\n",
      "Epoch: 2, Train Loss: 1.3040871404946423e-05\n",
      "Epoch: 2, Validation Loss: 7.426872605473542e-06\n",
      "Epoch: 3, Train Loss: 9.9779275791867e-06\n",
      "Epoch: 3, Validation Loss: 1.2516276217555673e-05\n",
      "Epoch: 4, Train Loss: 1.1501791354881412e-05\n",
      "Epoch: 4, Validation Loss: 5.134704999597215e-06\n",
      "Epoch: 5, Train Loss: 8.73121954395231e-06\n",
      "Epoch: 5, Validation Loss: 1.4433010138496717e-05\n",
      "Epoch: 6, Train Loss: 8.971870286236366e-06\n",
      "Epoch: 6, Validation Loss: 1.490571571497837e-05\n",
      "Epoch: 7, Train Loss: 8.396831447215787e-06\n",
      "Epoch: 7, Validation Loss: 1.0088203617889289e-05\n",
      "Epoch: 8, Train Loss: 7.895328985638278e-06\n",
      "Epoch: 8, Validation Loss: 2.4446981652200148e-06\n",
      "Epoch: 9, Train Loss: 6.3159804538541915e-06\n",
      "Epoch: 9, Validation Loss: 5.02428354882844e-06\n",
      "Epoch: 10, Train Loss: 6.129660373629978e-06\n",
      "Epoch: 10, Validation Loss: 4.738624029760848e-06\n",
      "Epoch: 11, Train Loss: 5.651360651786858e-06\n",
      "Epoch: 11, Validation Loss: 2.8727343085306344e-06\n",
      "Epoch: 12, Train Loss: 5.083254536895299e-06\n",
      "Epoch: 12, Validation Loss: 1.7127916427246294e-06\n",
      "Epoch: 13, Train Loss: 5.125306507309544e-06\n",
      "Epoch: 13, Validation Loss: 1.0011566048699629e-05\n",
      "Epoch: 14, Train Loss: 5.555982497477263e-06\n",
      "Epoch: 14, Validation Loss: 1.7761192274153123e-06\n",
      "Epoch: 15, Train Loss: 3.826579247995467e-06\n",
      "Epoch: 15, Validation Loss: 8.736017650934331e-06\n",
      "Epoch: 16, Train Loss: 4.783136546651262e-06\n",
      "Epoch: 16, Validation Loss: 9.00949755320585e-06\n",
      "Epoch: 17, Train Loss: 4.385222951759908e-06\n",
      "Epoch: 17, Validation Loss: 1.8438485429372563e-06\n",
      "Epoch: 18, Train Loss: 3.986986766256531e-06\n",
      "Epoch: 18, Validation Loss: 3.451706990555299e-06\n",
      "Epoch: 19, Train Loss: 3.483100866466946e-06\n",
      "Epoch: 19, Validation Loss: 1.9346408213385767e-06\n",
      "Epoch: 20, Train Loss: 4.192474749872628e-06\n",
      "Epoch: 20, Validation Loss: 1.8643885298320994e-06\n",
      "Epoch: 21, Train Loss: 3.1986135453715392e-06\n",
      "Epoch: 21, Validation Loss: 6.44990255158594e-06\n",
      "Epoch: 22, Train Loss: 4.344429194716317e-06\n",
      "Epoch: 22, Validation Loss: 8.825227285808058e-07\n",
      "Epoch: 23, Train Loss: 3.6544363623157418e-06\n",
      "Epoch: 23, Validation Loss: 2.0935108925984687e-06\n",
      "Epoch: 24, Train Loss: 2.3052628589098107e-06\n",
      "Epoch: 24, Validation Loss: 9.598464877112534e-07\n",
      "Epoch: 25, Train Loss: 3.238000613037761e-06\n",
      "Epoch: 25, Validation Loss: 6.585180886529572e-07\n",
      "Epoch: 26, Train Loss: 2.7946802984938494e-06\n",
      "Epoch: 26, Validation Loss: 1.6999073698138711e-06\n",
      "Epoch: 27, Train Loss: 2.6787183835922473e-06\n",
      "Epoch: 27, Validation Loss: 6.574408618499779e-06\n",
      "Epoch: 28, Train Loss: 2.7784603446365896e-06\n",
      "Epoch: 28, Validation Loss: 1.923197791826382e-06\n",
      "Epoch: 29, Train Loss: 2.6198442924809064e-06\n",
      "Epoch: 29, Validation Loss: 1.8131849976158156e-06\n",
      "Epoch: 30, Train Loss: 2.07305479306736e-06\n",
      "Epoch: 30, Validation Loss: 1.3332678639226197e-05\n",
      "Epoch: 31, Train Loss: 2.8332253298701223e-06\n",
      "Epoch: 31, Validation Loss: 1.3320236317483156e-05\n",
      "Epoch: 32, Train Loss: 2.187388936656086e-06\n",
      "Epoch: 32, Validation Loss: 6.377466886722723e-07\n",
      "Epoch: 33, Train Loss: 2.4962485094851496e-06\n",
      "Epoch: 33, Validation Loss: 1.919715430898005e-06\n",
      "Epoch: 34, Train Loss: 2.339526035067446e-06\n",
      "Epoch: 34, Validation Loss: 1.1569018688366344e-05\n",
      "Epoch: 35, Train Loss: 1.9123525446093097e-06\n",
      "Epoch: 35, Validation Loss: 2.041019847484447e-06\n",
      "Epoch: 36, Train Loss: 2.0847881042939107e-06\n",
      "Epoch: 36, Validation Loss: 2.9697698061767824e-06\n",
      "Epoch: 37, Train Loss: 1.8920345130044181e-06\n",
      "Epoch: 37, Validation Loss: 2.262820447424009e-06\n",
      "Epoch: 38, Train Loss: 2.077656078512188e-06\n",
      "Epoch: 38, Validation Loss: 1.809880711324437e-06\n",
      "Epoch: 39, Train Loss: 1.7971906507808768e-06\n",
      "Epoch: 39, Validation Loss: 3.0678241072165613e-06\n",
      "Epoch: 40, Train Loss: 1.965892236733358e-06\n",
      "Epoch: 40, Validation Loss: 2.179758962620198e-06\n",
      "Epoch: 41, Train Loss: 1.768481735783875e-06\n",
      "Epoch: 41, Validation Loss: 2.300771539441936e-06\n",
      "At temperature 15 the loss is 0.0008660835586624671\n",
      "At temperature 25 the loss is 0.0007925404889564644\n",
      "At temperature 45 the loss is 0.000805143941099893\n",
      "At temperature 15 the loss is 0.0009059586574783845\n",
      "At temperature 25 the loss is 0.0008328958060288146\n",
      "At temperature 45 the loss is 0.0007159314167314402\n",
      "Number of no improvement trials is 6\n",
      "Trial 18/100 completed. Remaining trials: 82\n",
      "Trial parameters\n",
      "{'num_layers': 5, 'num_neurons': 173, 'sequence_length': 2, 'batch_size': 32, 'epochs': 21, 'lr': 0.00034042131577787416}\n",
      "Epoch: 1, Train Loss: 0.0002739777880283273\n",
      "Epoch: 1, Validation Loss: 2.1292169490430797e-05\n",
      "Epoch: 2, Train Loss: 1.181630649315297e-05\n",
      "Epoch: 2, Validation Loss: 4.524172619364695e-06\n",
      "Epoch: 3, Train Loss: 6.439500512248985e-06\n",
      "Epoch: 3, Validation Loss: 1.424800667752549e-06\n",
      "Epoch: 4, Train Loss: 4.396382566425686e-06\n",
      "Epoch: 4, Validation Loss: 2.476545097001901e-06\n",
      "Epoch: 5, Train Loss: 3.4886757405150518e-06\n",
      "Epoch: 5, Validation Loss: 3.5137343171603397e-06\n",
      "Epoch: 6, Train Loss: 2.9393792227131653e-06\n",
      "Epoch: 6, Validation Loss: 8.350291096700853e-06\n",
      "Epoch: 7, Train Loss: 2.403951031935501e-06\n",
      "Epoch: 7, Validation Loss: 1.3235362685438381e-06\n",
      "Epoch: 8, Train Loss: 2.238736199426115e-06\n",
      "Epoch: 8, Validation Loss: 3.651924009578686e-06\n",
      "Epoch: 9, Train Loss: 1.9398723363634714e-06\n",
      "Epoch: 9, Validation Loss: 2.9461965887442406e-06\n",
      "Epoch: 10, Train Loss: 1.7469657636684472e-06\n",
      "Epoch: 10, Validation Loss: 2.8619234789493066e-06\n",
      "Epoch: 11, Train Loss: 1.6681158230987512e-06\n",
      "Epoch: 11, Validation Loss: 3.183050825682068e-07\n",
      "Epoch: 12, Train Loss: 1.582224262795625e-06\n",
      "Epoch: 12, Validation Loss: 9.448358926153202e-07\n",
      "Epoch: 13, Train Loss: 1.4254280620813987e-06\n",
      "Epoch: 13, Validation Loss: 1.613356943308541e-06\n",
      "Epoch: 14, Train Loss: 1.3900125949184454e-06\n",
      "Epoch: 14, Validation Loss: 4.1174585347488204e-07\n",
      "Epoch: 15, Train Loss: 1.2999625227751548e-06\n",
      "Epoch: 15, Validation Loss: 1.4593658095005282e-06\n",
      "Epoch: 16, Train Loss: 1.2093743097121534e-06\n",
      "Epoch: 16, Validation Loss: 2.6283721744499204e-06\n",
      "Epoch: 17, Train Loss: 1.1769689652334458e-06\n",
      "Epoch: 17, Validation Loss: 1.267694530119124e-06\n",
      "Epoch: 18, Train Loss: 1.0697000268124484e-06\n",
      "Epoch: 18, Validation Loss: 5.496686995872153e-07\n",
      "Epoch: 19, Train Loss: 1.0529159596720206e-06\n",
      "Epoch: 19, Validation Loss: 5.902152597453348e-07\n",
      "Epoch: 20, Train Loss: 1.0478248745145458e-06\n",
      "Epoch: 20, Validation Loss: 2.9168237036362293e-07\n",
      "Epoch: 21, Train Loss: 1.0155856975079156e-06\n",
      "Epoch: 21, Validation Loss: 6.071255156368112e-07\n",
      "At temperature 15 the loss is 0.0008276816467462974\n",
      "At temperature 25 the loss is 0.0007881146798154223\n",
      "At temperature 45 the loss is 0.0007718599610536165\n",
      "At temperature 15 the loss is 0.000848445333399213\n",
      "At temperature 25 the loss is 0.0007983319060046999\n",
      "At temperature 45 the loss is 0.0007234733373240551\n",
      "Number of no improvement trials is 7\n",
      "Trial 19/100 completed. Remaining trials: 81\n",
      "Trial parameters\n",
      "{'num_layers': 3, 'num_neurons': 70, 'sequence_length': 5, 'batch_size': 32, 'epochs': 27, 'lr': 0.0004307827727461392}\n",
      "Epoch: 1, Train Loss: 0.00032509142440863216\n",
      "Epoch: 1, Validation Loss: 4.470608630739745e-06\n",
      "Epoch: 2, Train Loss: 7.123734464989319e-06\n",
      "Epoch: 2, Validation Loss: 1.4234260543894263e-05\n",
      "Epoch: 3, Train Loss: 4.275440496286827e-06\n",
      "Epoch: 3, Validation Loss: 1.3146881560414376e-05\n",
      "Epoch: 4, Train Loss: 3.306254721444932e-06\n",
      "Epoch: 4, Validation Loss: 3.1221170409541853e-06\n",
      "Epoch: 5, Train Loss: 2.5803802161541068e-06\n",
      "Epoch: 5, Validation Loss: 1.9190812645378157e-06\n",
      "Epoch: 6, Train Loss: 2.2816963309900724e-06\n",
      "Epoch: 6, Validation Loss: 1.1219025761944477e-06\n",
      "Epoch: 7, Train Loss: 2.124705230800869e-06\n",
      "Epoch: 7, Validation Loss: 2.6312331506129076e-06\n",
      "Epoch: 8, Train Loss: 1.99851407373711e-06\n",
      "Epoch: 8, Validation Loss: 9.535356786311649e-07\n",
      "Epoch: 9, Train Loss: 1.691162438352888e-06\n",
      "Epoch: 9, Validation Loss: 1.3968913908343315e-06\n",
      "Epoch: 10, Train Loss: 1.6773928835203535e-06\n",
      "Epoch: 10, Validation Loss: 9.348154282160986e-07\n",
      "Epoch: 11, Train Loss: 1.434329764138196e-06\n",
      "Epoch: 11, Validation Loss: 1.1937339854530856e-06\n",
      "Epoch: 12, Train Loss: 1.3715237876939264e-06\n",
      "Epoch: 12, Validation Loss: 3.2592094330588073e-06\n",
      "Epoch: 13, Train Loss: 1.2456418084006076e-06\n",
      "Epoch: 13, Validation Loss: 2.4707404658262383e-06\n",
      "Epoch: 14, Train Loss: 1.1893800055800136e-06\n",
      "Epoch: 14, Validation Loss: 2.342678398847182e-06\n",
      "Epoch: 15, Train Loss: 1.1173818207597566e-06\n",
      "Epoch: 15, Validation Loss: 4.1351189531303335e-07\n",
      "Epoch: 16, Train Loss: 1.0524909989253812e-06\n",
      "Epoch: 16, Validation Loss: 3.6810392976034466e-07\n",
      "Epoch: 17, Train Loss: 1.0444637770115185e-06\n",
      "Epoch: 17, Validation Loss: 9.720645400868138e-07\n",
      "Epoch: 18, Train Loss: 1.0292973817708766e-06\n",
      "Epoch: 18, Validation Loss: 2.716243359758717e-06\n",
      "Epoch: 19, Train Loss: 9.192120107407831e-07\n",
      "Epoch: 19, Validation Loss: 1.1258985523163648e-06\n",
      "Epoch: 20, Train Loss: 9.2278182659855e-07\n",
      "Epoch: 20, Validation Loss: 4.414511473928495e-07\n",
      "Epoch: 21, Train Loss: 8.715590509648135e-07\n",
      "Epoch: 21, Validation Loss: 4.209594678585452e-07\n",
      "Epoch: 22, Train Loss: 8.804403755972431e-07\n",
      "Epoch: 22, Validation Loss: 2.883962019826899e-07\n",
      "Epoch: 23, Train Loss: 8.027343390778347e-07\n",
      "Epoch: 23, Validation Loss: 2.8514788404936146e-07\n",
      "Epoch: 24, Train Loss: 8.380932321591899e-07\n",
      "Epoch: 24, Validation Loss: 4.0464445988163046e-07\n",
      "Epoch: 25, Train Loss: 7.68686761953998e-07\n",
      "Epoch: 25, Validation Loss: 9.05237755790555e-07\n",
      "Epoch: 26, Train Loss: 7.73133049902961e-07\n",
      "Epoch: 26, Validation Loss: 5.87336528990448e-07\n",
      "Epoch: 27, Train Loss: 7.355755269129653e-07\n",
      "Epoch: 27, Validation Loss: 5.603309259825121e-07\n",
      "At temperature 15 the loss is 0.0008487091940313528\n",
      "At temperature 25 the loss is 0.0008137554684675303\n",
      "At temperature 45 the loss is 0.0007931882345321272\n",
      "At temperature 15 the loss is 0.0008273792206629105\n",
      "At temperature 25 the loss is 0.0007753112236799965\n",
      "At temperature 45 the loss is 0.0007154644677553584\n",
      "Number of no improvement trials is 8\n",
      "Trial 20/100 completed. Remaining trials: 80\n",
      "Trial parameters\n",
      "{'num_layers': 2, 'num_neurons': 133, 'sequence_length': 3, 'batch_size': 32, 'epochs': 44, 'lr': 0.00015564831502456}\n",
      "Epoch: 1, Train Loss: 0.00039983931992741646\n",
      "Epoch: 1, Validation Loss: 5.211392852499721e-05\n",
      "Epoch: 2, Train Loss: 1.042033992933178e-05\n",
      "Epoch: 2, Validation Loss: 2.1349882591245556e-05\n",
      "Epoch: 3, Train Loss: 5.716824008092951e-06\n",
      "Epoch: 3, Validation Loss: 1.2344757210198188e-06\n",
      "Epoch: 4, Train Loss: 3.847260129193934e-06\n",
      "Epoch: 4, Validation Loss: 2.439028334648991e-06\n",
      "Epoch: 5, Train Loss: 3.041723279223265e-06\n",
      "Epoch: 5, Validation Loss: 1.0845962822077001e-06\n",
      "Epoch: 6, Train Loss: 2.5565965312540366e-06\n",
      "Epoch: 6, Validation Loss: 6.044397908346083e-07\n",
      "Epoch: 7, Train Loss: 2.1646601752355254e-06\n",
      "Epoch: 7, Validation Loss: 8.136526384089337e-07\n",
      "Epoch: 8, Train Loss: 1.8475000826442534e-06\n",
      "Epoch: 8, Validation Loss: 1.7893559588889053e-06\n",
      "Epoch: 9, Train Loss: 1.6006009205576072e-06\n",
      "Epoch: 9, Validation Loss: 4.64113916005716e-06\n",
      "Epoch: 10, Train Loss: 1.5059928147174698e-06\n",
      "Epoch: 10, Validation Loss: 9.90629002353198e-07\n",
      "Epoch: 11, Train Loss: 1.3551041194948605e-06\n",
      "Epoch: 11, Validation Loss: 5.321923354655994e-07\n",
      "Epoch: 12, Train Loss: 1.234103599905876e-06\n",
      "Epoch: 12, Validation Loss: 7.472684159482866e-07\n",
      "Epoch: 13, Train Loss: 1.1445971491777778e-06\n",
      "Epoch: 13, Validation Loss: 6.201930411922094e-07\n",
      "Epoch: 14, Train Loss: 1.0037165724508466e-06\n",
      "Epoch: 14, Validation Loss: 3.909723715655674e-07\n",
      "Epoch: 15, Train Loss: 9.91115082619936e-07\n",
      "Epoch: 15, Validation Loss: 5.647124944191884e-07\n",
      "Epoch: 16, Train Loss: 9.214634733122006e-07\n",
      "Epoch: 16, Validation Loss: 7.181027685380523e-07\n",
      "Epoch: 17, Train Loss: 8.572782010563444e-07\n",
      "Epoch: 17, Validation Loss: 6.793134286524147e-07\n",
      "Epoch: 18, Train Loss: 8.360122538559267e-07\n",
      "Epoch: 18, Validation Loss: 3.9156526637370076e-07\n",
      "Epoch: 19, Train Loss: 7.978588321199195e-07\n",
      "Epoch: 19, Validation Loss: 2.603732239556477e-07\n",
      "Epoch: 20, Train Loss: 7.538439716808626e-07\n",
      "Epoch: 20, Validation Loss: 3.321567657775433e-07\n",
      "Epoch: 21, Train Loss: 7.434423024467303e-07\n",
      "Epoch: 21, Validation Loss: 3.3620002811817767e-07\n",
      "Epoch: 22, Train Loss: 6.923619474774216e-07\n",
      "Epoch: 22, Validation Loss: 3.349191453685119e-07\n",
      "Epoch: 23, Train Loss: 6.646765157588352e-07\n",
      "Epoch: 23, Validation Loss: 7.032996986601887e-07\n",
      "Epoch: 24, Train Loss: 6.440048568620986e-07\n",
      "Epoch: 24, Validation Loss: 5.312834112075423e-07\n",
      "Epoch: 25, Train Loss: 6.547292347565342e-07\n",
      "Epoch: 25, Validation Loss: 7.14217655272842e-07\n",
      "Epoch: 26, Train Loss: 6.049698928378549e-07\n",
      "Epoch: 26, Validation Loss: 3.014851543385361e-07\n",
      "Epoch: 27, Train Loss: 5.919368367235435e-07\n",
      "Epoch: 27, Validation Loss: 1.2175696623199005e-06\n",
      "Epoch: 28, Train Loss: 5.959770367648112e-07\n",
      "Epoch: 28, Validation Loss: 5.840676924507741e-07\n",
      "Epoch: 29, Train Loss: 5.794911188086825e-07\n",
      "Epoch: 29, Validation Loss: 3.0306905912912806e-07\n",
      "Epoch: 30, Train Loss: 5.726459487450637e-07\n",
      "Epoch: 30, Validation Loss: 6.158577930540024e-07\n",
      "Epoch: 31, Train Loss: 5.436532601472844e-07\n",
      "Epoch: 31, Validation Loss: 7.034559695262706e-07\n",
      "Epoch: 32, Train Loss: 5.504004603689523e-07\n",
      "Epoch: 32, Validation Loss: 3.439931427074894e-07\n",
      "Epoch: 33, Train Loss: 5.17905306177748e-07\n",
      "Epoch: 33, Validation Loss: 6.200246830652717e-07\n",
      "Epoch: 34, Train Loss: 5.203626186468731e-07\n",
      "Epoch: 34, Validation Loss: 3.2032316146169657e-07\n",
      "Epoch: 35, Train Loss: 5.037131582782351e-07\n",
      "Epoch: 35, Validation Loss: 3.48124594550872e-07\n",
      "Epoch: 36, Train Loss: 4.972839608486666e-07\n",
      "Epoch: 36, Validation Loss: 8.12707596186772e-07\n",
      "Epoch: 37, Train Loss: 4.733280901369379e-07\n",
      "Epoch: 37, Validation Loss: 4.2327179335717224e-07\n",
      "Epoch: 38, Train Loss: 4.874516354832102e-07\n",
      "Epoch: 38, Validation Loss: 6.942335657148923e-07\n",
      "Epoch: 39, Train Loss: 4.639274947102101e-07\n",
      "Epoch: 39, Validation Loss: 3.2152226318261653e-07\n",
      "Epoch: 40, Train Loss: 4.6738674286803957e-07\n",
      "Epoch: 40, Validation Loss: 3.76483639945158e-07\n",
      "Epoch: 41, Train Loss: 4.412175147226638e-07\n",
      "Epoch: 41, Validation Loss: 2.2394171288998897e-07\n",
      "Epoch: 42, Train Loss: 4.540597659730713e-07\n",
      "Epoch: 42, Validation Loss: 3.4064512594332584e-07\n",
      "Epoch: 43, Train Loss: 4.275153384366449e-07\n",
      "Epoch: 43, Validation Loss: 2.2191254055006972e-07\n",
      "Epoch: 44, Train Loss: 4.29126382080571e-07\n",
      "Epoch: 44, Validation Loss: 3.681140047914757e-07\n",
      "At temperature 15 the loss is 0.00083582269251877\n",
      "At temperature 25 the loss is 0.0007875078615849054\n",
      "At temperature 45 the loss is 0.0007792427445565409\n",
      "At temperature 15 the loss is 0.0008372269602227856\n",
      "At temperature 25 the loss is 0.000796409603081926\n",
      "At temperature 45 the loss is 0.0007284521037553377\n",
      "Number of no improvement trials is 9\n",
      "Trial 21/100 completed. Remaining trials: 79\n",
      "Trial parameters\n",
      "{'num_layers': 5, 'num_neurons': 174, 'sequence_length': 2, 'batch_size': 32, 'epochs': 19, 'lr': 0.00027724282313905976}\n",
      "Epoch: 1, Train Loss: 0.00036286657088962896\n",
      "Epoch: 1, Validation Loss: 1.3622569986619678e-05\n",
      "Epoch: 2, Train Loss: 1.3289878474427624e-05\n",
      "Epoch: 2, Validation Loss: 2.3821164309433687e-06\n",
      "Epoch: 3, Train Loss: 6.488624934885536e-06\n",
      "Epoch: 3, Validation Loss: 6.462422536097551e-06\n",
      "Epoch: 4, Train Loss: 4.1921607452176575e-06\n",
      "Epoch: 4, Validation Loss: 8.50865929986901e-07\n",
      "Epoch: 5, Train Loss: 3.3787212453064428e-06\n",
      "Epoch: 5, Validation Loss: 9.562541964732605e-07\n",
      "Epoch: 6, Train Loss: 2.874986342741029e-06\n",
      "Epoch: 6, Validation Loss: 2.158948424828699e-06\n",
      "Epoch: 7, Train Loss: 2.3815613090757874e-06\n",
      "Epoch: 7, Validation Loss: 1.9661015992960555e-06\n",
      "Epoch: 8, Train Loss: 2.1553413260856356e-06\n",
      "Epoch: 8, Validation Loss: 3.425033542912966e-06\n",
      "Epoch: 9, Train Loss: 1.8627945742907006e-06\n",
      "Epoch: 9, Validation Loss: 9.12559448258881e-07\n",
      "Epoch: 10, Train Loss: 1.7090452250997535e-06\n",
      "Epoch: 10, Validation Loss: 6.206126969939312e-07\n",
      "Epoch: 11, Train Loss: 1.5003875275735949e-06\n",
      "Epoch: 11, Validation Loss: 4.084892635398627e-07\n",
      "Epoch: 12, Train Loss: 1.4355435772869363e-06\n",
      "Epoch: 12, Validation Loss: 4.1362062619171724e-07\n",
      "Epoch: 13, Train Loss: 1.3061829358930278e-06\n",
      "Epoch: 13, Validation Loss: 4.04251735506136e-07\n",
      "Epoch: 14, Train Loss: 1.2522099512898507e-06\n",
      "Epoch: 14, Validation Loss: 2.6031666733807524e-06\n",
      "Epoch: 15, Train Loss: 1.116788329834932e-06\n",
      "Epoch: 15, Validation Loss: 3.9539412037328976e-07\n",
      "Epoch: 16, Train Loss: 1.0719828561549578e-06\n",
      "Epoch: 16, Validation Loss: 5.325892746937711e-07\n",
      "Epoch: 17, Train Loss: 9.77851107613118e-07\n",
      "Epoch: 17, Validation Loss: 5.834900322344086e-07\n",
      "Epoch: 18, Train Loss: 9.71445412580723e-07\n",
      "Epoch: 18, Validation Loss: 7.833509038477912e-07\n",
      "Epoch: 19, Train Loss: 9.141554605648314e-07\n",
      "Epoch: 19, Validation Loss: 1.250173850720998e-06\n",
      "At temperature 15 the loss is 0.0008015303298033138\n",
      "At temperature 25 the loss is 0.0007735538283503333\n",
      "At temperature 45 the loss is 0.0007542430662345561\n",
      "At temperature 15 the loss is 0.0008652246950421232\n",
      "At temperature 25 the loss is 0.0008089450921245369\n",
      "At temperature 45 the loss is 0.0007357799561354821\n",
      "Number of no improvement trials is 10\n",
      "No improvement in the last 10 trials. Stopping...\n",
      "Best trial:\n",
      "  Value:  0.0007693429851019061\n",
      "  Params: \n",
      "    num_layers: 4\n",
      "    num_neurons: 98\n",
      "    sequence_length: 1\n",
      "    batch_size: 32\n",
      "    epochs: 24\n",
      "    lr: 0.00010015355883120207\n"
     ]
    }
   ],
   "source": [
    "# Run objective function\n",
    "n_trials = 100 # number of trials to train the cnn\n",
    "study = optuna.create_study(direction='minimize') # the purpose is to minimize the loss\n",
    "\n",
    "# Define variables to store the best model, training loss value and best parameters\n",
    "best_model = None \n",
    "best_value = float(\"inf\")\n",
    "best_params = None\n",
    "\n",
    "# If no improvement in consecutively 10 trials then drop the training\n",
    "no_improvement_trials = 0\n",
    "max_no_improvement_trials = 10\n",
    "\n",
    "# Loop over the trials \n",
    "for i in range(n_trials):\n",
    "    trial = study.ask()\n",
    "    value, model, params = objective(trial, training_data=data, testing_data=datasets)\n",
    "    study.tell(trial, value)\n",
    "    if value < best_value:\n",
    "        best_value = value\n",
    "        best_model = model\n",
    "        best_params = params\n",
    "        no_improvement_trials = 0\n",
    "    else:\n",
    "        no_improvement_trials += 1\n",
    "        print(f\"Number of no improvement trials is {no_improvement_trials}\")\n",
    "    if no_improvement_trials >= max_no_improvement_trials:\n",
    "        print(f\"No improvement in the last {no_improvement_trials} trials. Stopping...\")\n",
    "        break\n",
    "\n",
    "    print(f'Trial {i+1}/{n_trials} completed. Remaining trials: {n_trials - i - 1}')\n",
    "\n",
    "best_trial = study.best_trial\n",
    "\n",
    "# Print the found parameters\n",
    "print('Best trial:')\n",
    "print('  Value: ', best_trial.value)\n",
    "print('  Params: ')\n",
    "for key, value in best_trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "torch.save(best_model.state_dict(), 'best_cnn_ecm_trained.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ba_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
